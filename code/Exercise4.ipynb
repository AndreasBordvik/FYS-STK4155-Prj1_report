{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 4: Ridge Regression on the Franke function with resampling (score 20 points)\n",
    "\n",
    "Write your own code for the Ridge method, either using matrix inversion or the singular value decomposition as done in the previous exercise. Perform the same bootstrap analysis as in the Exercise 2 (for the same polynomials) and the cross-validation in exercise 3 but now for different values of λ. Compare and analyze your results with those obtained in exercises 1-3. Study the dependence on λ.\n",
    "\n",
    "Study also the bias-variance trade-off as function of various values of the parameter λ. For the bias-variance trade-off, use the bootstrap resampling method. Comment your results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from common import *\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import os\n",
    "#import seaborn as sns\n",
    "\n",
    "print(f\"Root directory: {os.getcwd()}\")\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "    \"font.size\": 10,\n",
    "})\n",
    "\n",
    "%matplotlib inline "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Data\n",
    "Defining and creating the data\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#generate some data:\n",
    "np.random.seed(SEED_VALUE)\n",
    "n = 20\n",
    "x = np.sort(np.random.uniform(0, 1, n))\n",
    "y = np.sort(np.random.uniform(0, 1, n))\n",
    "x,y = np.meshgrid(x,y)\n",
    "t_nonoise = FrankeFunction(x, y)\n",
    "t = t_nonoise + noise_factor(n, factor=0.2)\n",
    "degree = 12\n",
    "min_lambda = -9\n",
    "max_lambda = 4\n",
    "nlambdas = 500\n",
    "lambdas = np.logspace(min_lambda,max_lambda, nlambdas)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_mse = np.zeros((degree, nlambdas))\n",
    "train_mse = np.zeros_like(test_mse)\n",
    "model_list = np.empty_like(test_mse, dtype=object)\n",
    "optimal_deg = 0\n",
    "optimal_lmb = 0\n",
    "lambda_degree = 0\n",
    "best_mse = np.inf\n",
    "\n",
    "for deg in range(1, degree+1):\n",
    "    for lmb in range(len(lambdas)):\n",
    "\n",
    "        X = create_X(x,y,n=deg)\n",
    "\n",
    "        X_train, X_test, z_train, z_test = prepare_data(X, t.ravel(), scale_X=True, skip_intercept=True)\n",
    "\n",
    "        model = RidgeRegression(lambdas[lmb])\n",
    "        z_hat_train = model.fit(X_train, z_train)\n",
    "        z_hat_test = model.predict(X_test)\n",
    "\n",
    "        test_mse[deg-1,lmb] = MSE(z_test, z_hat_test)\n",
    "        train_mse[deg-1, lmb] = MSE(z_train, z_hat_train)\n",
    "        model_list[deg-1,lmb] = model\n",
    "        \n",
    "        if test_mse[deg-1,lmb] < best_mse:\n",
    "            best_mse = test_mse[deg-1, lmb]\n",
    "            optimal_deg = deg\n",
    "            optimal_lmb = lambdas[lmb]\n",
    "            lambda_degree = lmb\n",
    "\n",
    "print(best_mse)\n",
    "print(optimal_lmb)\n",
    "print(optimal_deg)\n",
    "print(train_mse[deg-1, lmb])\n",
    "optimal_model = model_list[deg-1, lambda_degree]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Surface-plot of optimal lambda"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.title.set_text(\"Plot of the Search Landscape\")\n",
    "ax.set_xlabel(\"Degree\"); ax.set_ylabel(\"Lambda\"); ax.set_zlabel(\"MSE\")\n",
    "\n",
    "degs, lambs = np.meshgrid(range(degree), range(nlambdas))\n",
    "print(degs.shape)\n",
    "print(lambs.shape)\n",
    "print(test_mse.shape)\n",
    "surf = ax.plot_surface(degs, lambs, test_mse.swapaxes(0,1), cmap=cm.coolwarm)\n",
    "ax.scatter(5, 0, best_mse, c='y', marker='*', s=2000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Betaplot showing effect of ridge"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "summaries_df = pd.DataFrame()\n",
    "\n",
    "for lmb in lambdas:\n",
    "    X = create_X(x,y,n=4)\n",
    "    X_train, X_test, z_train, z_test = prepare_data(X, t.ravel(), scale_X=True, skip_intercept=True)\n",
    "    model = RidgeRegression(lmb)\n",
    "    model.fit(X_train, z_train)\n",
    "    summary_df = model.summary()\n",
    "    summaries_df = pd.concat([summaries_df, summary_df], axis=0)\n",
    "\n",
    "fig = plot_beta_errors_for_lambdas(summaries_df, 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some code that implements the brute force lambda selection, this is inspired by the lecture 30.09"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# NO NOISE\n",
    "\n",
    "X = create_X(x,y,degree)\n",
    "X_train, X_test, t_train, t_test = prepare_data(X,t_nonoise.ravel(), scale_X=True, skip_intercept=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "MSERidgePredict = np.zeros(nlambdas)\n",
    "MSEOurRidge = np.zeros(nlambdas)\n",
    "lambdas = np.logspace(min_lambda, max_lambda, nlambdas)\n",
    "for i in range(nlambdas):\n",
    "    lmb = lambdas[i]\n",
    "\n",
    "    # SKlearn\n",
    "    RegRidge = lm.Ridge(lmb,fit_intercept=False) # ALWAYS keep intercept False\n",
    "    RegRidge.fit(X_train, t_train)\n",
    "    tpredictRidge = RegRidge.predict(X_test)\n",
    "    MSERidgePredict[i] = MSE(t_test, tpredictRidge)\n",
    "\n",
    "    # our Ridge\n",
    "    model = RidgeRegression(lmb)\n",
    "    model.fit(X_train, t_train)\n",
    "    tpredictOur = model.predict(X_test)\n",
    "    MSEOurRidge[i] = MSE(t_test, tpredictOur)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.log10(lambdas), MSERidgePredict, 'g', label = 'MSE SL Ridge Test')\n",
    "plt.plot(np.log10(lambdas), MSEOurRidge, 'r--', label = \"MSE Our Ridge Test\")\n",
    "plt.xlabel('log10(lambda)')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparing with gridSearch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = lm.Ridge(fit_intercept=False)\n",
    "gridsearch = GridSearchCV(estimator=model, param_grid=dict(alpha=lambdas))\n",
    "gridsearch.fit(X_train, t_train)\n",
    "print(gridsearch)\n",
    "ypredictRidge = gridsearch.predict(X_test)\n",
    "# summarize the results of the grid search\n",
    "print(f\"Best estimated lambda-value: {np.log10(gridsearch.best_estimator_.alpha)}\")\n",
    "print(f\"MSE score: {MSE(t_test,ypredictRidge)}\")\n",
    "print(f\"R2 score: {R2(t_test,ypredictRidge)}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# NOISE and OLS for comparison\n",
    "\n",
    "X = create_X(x,y,degree)\n",
    "X_train, X_test, t_train, t_test = prepare_data(X,t.ravel(), scale_X=True, skip_intercept=True)\n",
    "\n",
    "#X_train = X_train[:,1:]\n",
    "#X_test = X_test[:,1:]\n",
    "\n",
    "nlambdas = 500\n",
    "MSERidgePredict = np.zeros(nlambdas)\n",
    "MSEOurRidge = np.zeros(nlambdas)\n",
    "MSEols = np.zeros(nlambdas)\n",
    "lambdas = np.logspace(min_lambda, max_lambda, nlambdas)\n",
    "for i in range(nlambdas):\n",
    "    lmb = lambdas[i]\n",
    "\n",
    "    # SKlearn\n",
    "    RegRidge = lm.Ridge(lmb,fit_intercept=False) # ALWAYS keep intercept False\n",
    "    RegRidge.fit(X_train, t_train)\n",
    "    tpredictRidge = RegRidge.predict(X_test)\n",
    "    MSERidgePredict[i] = MSE(t_test, tpredictRidge)\n",
    "\n",
    "    # our Ridge\n",
    "    model = RidgeRegression(lmb)\n",
    "    model.fit(X_train, t_train)\n",
    "    tpredictOur = model.predict(X_test)\n",
    "    MSEOurRidge[i] = MSE(t_test, tpredictOur)\n",
    "\n",
    "    # OLS :)\n",
    "    \"\"\"\n",
    "    ols = OLS()\n",
    "    ols.fit(X_train, t_train)\n",
    "    olspredict = ols.predict(X_test)\n",
    "    MSEols[i] = MSE(t_test, olspredict)\n",
    "    \"\"\"\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.log10(lambdas), MSERidgePredict, 'g', label = 'MSE SL Ridge Test')\n",
    "plt.plot(np.log10(lambdas), MSEOurRidge, 'r--', label = \"MSE Our Ridge Test\")\n",
    "#plt.plot(np.log10(lambdas), MSEols, 'b--', label = \"MSE Our OLS Test\")\n",
    "plt.xlabel('log10(lambda)')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bootstrapping\n",
    "using lambda optimal equal to -9, for different degrees"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.random.seed(SEED_VALUE)\n",
    "maxdegree = 13\n",
    "n_bootstraps = 40\n",
    "lmb = np.log10(1e-9)\n",
    "n = 20\n",
    "x = np.sort(np.random.uniform(0, 1, n))\n",
    "y = np.sort(np.random.uniform(0, 1, n))\n",
    "x,y = np.meshgrid(x,y)\n",
    "z = FrankeFunction(x,y) + noise_factor(n, factor=0.05)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "polydegree = np.arange(1, maxdegree+1)\n",
    "MSE_test, MSE_train, bias, variance = bootstrap(x, y, z, maxdegree, n_bootstraps, RidgeRegression(lmb), scale_X=True, skip_intercept=True)\n",
    "\n",
    "plt.plot(polydegree, MSE_test,\"m\", label='MSE test')\n",
    "plt.plot(polydegree, MSE_train,\"c\", label='MSE train')\n",
    "plt.plot(polydegree, bias,\"b--\", label='bias')\n",
    "plt.plot(polydegree, variance,\"r--\", label='Variance')\n",
    "#plt.plot(polydegree, bias+variance,\"g--\", label='bias+variance')\n",
    "\n",
    "plt.xlabel(\"Model complexity / Polynomial Degree\")\n",
    "plt.ylabel(\"Prediction Error - MSE\")\n",
    "plt.xticks(polydegree)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(f\"{REPORT_FIGURES}{EX4}ridge_complexity_using_bootstrap_function.pdf\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Shouldn't OLS MSE for Noisy data be outperformed by Ridge?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "for lmb in lambdas:\n",
    "    boot_strp_MSE_test, _, _, boot_strp_variance = bootstrap(x, y, t, degree, 20, RidgeRegression(lmb))\n",
    "    boot_strp_std = np.sqrt(boot_strp_variance)\n",
    "\n",
    "    for degree in range(1,degree):\n",
    "        X = create_X(x,y,degree)\n",
    "    \n",
    "    \n",
    "        mean_folds_error = np.zeros(6)\n",
    "        mse_std_arr = np.zeros(6)\n",
    "        for folds in range(5,11):\n",
    "            #create LinearRegression model object from SK to use in sk.cross_val_score\n",
    "            sk_model = linear_model.Ridge(alpha=lmb)\n",
    "            #Get scores from SK crossval:\n",
    "            sk_scores = cross_val_score(sk_model, X, t.ravel(), cv=folds, scoring = \"neg_mean_squared_error\")\n",
    "        \n",
    "\n",
    "            implemented_scores = cross_val(k = folds, model = \"Ridge\",lmb=lmb, X = X, z = t, shuffle=True)\n",
    "            # plt.plot(np.arange(1,folds+1), implemented_scores,\"-o\", label = f\"Splitted in {folds} folds\")\n",
    "            # #plt.plot(np.arange(folds), sk_scores*-1,\"--o\", label = f\"{folds} folds(sk.cv)\")\n",
    "            # plt.xlabel(\"MSE at testfold number\")\n",
    "            # plt.ylabel(\"MSE\")\n",
    "            # plt.title(f\"Complexity degree: {degree} \")\n",
    "            # plt.ylim(0,1)\n",
    "            # plt.xticks(np.arange(1,folds+1))\n",
    "            # plt.grid(True)\n",
    "            # plt.legend()\n",
    "            mean_folds_error[folds-5] = np.mean(implemented_scores)\n",
    "            mse_std_arr[folds-5] = np.std(implemented_scores)\n",
    "            \n",
    "            \n",
    "        #plt.errorbar(np.arange(5,11), mean_folds_error, yerr = mse_std_arr, fmt='c--', ecolor='deeppink', capthick=2)\n",
    "        plt.plot(np.arange(5,11), np.ones(6)*boot_strp_MSE_test[degree],\"o\", label =\"Mean MSE bootstrap with STD\")\n",
    "        plt.fill_between(np.arange(5,11), np.ones(6)*boot_strp_MSE_test[degree]-boot_strp_std[degree],\n",
    "                        np.ones(6)*boot_strp_MSE_test[degree]+boot_strp_std[degree], alpha = 0.2 )\n",
    "        plt.plot(np.arange(5,11), mean_folds_error, \"o\",  label = \"Mean MSE CV with STD\")\n",
    "        plt.fill_between(np.arange(5,11), mean_folds_error-mse_std_arr, mean_folds_error+mse_std_arr,  alpha = 0.2, color = \"darkorange\")\n",
    "        plt.title(f\"Model complexity: {degree} degrees, log($\\lambda$):{np.log10(lmb)} \")\n",
    "        plt.xlabel(\"K-fold\")\n",
    "        plt.ylabel(\"MSE\")\n",
    "        plt.ylim(0,0.1)\n",
    "        plt.xticks(np.arange(5,11))\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Looking at beta values for optimal degree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "optimal_degree = 6\n",
    "min_lambda = -7 \n",
    "max_lambda = -3\n",
    "nbf_lambdas = 20\n",
    "lambdas = np.logspace(min_lambda,max_lambda, nbf_lambdas)\n",
    "summaries_df = pd.DataFrame()\n",
    "\n",
    "for lmb in lambdas:\n",
    "    #MSE_test = np.zeros(maxdegree)\n",
    "    #MSE_train = np.zeros(maxdegree)\n",
    "    #polydegree = np.arange(maxdegree)\n",
    "    #bias = np.zeros(maxdegree)\n",
    "    #variance = np.zeros(maxdegree)\n",
    "\n",
    "    X = create_X(x, y, n=optimal_degree)\n",
    "    X_train, X_test, z_train, z_test = prepare_data(X, t.ravel().reshape(-1,1), test_size=0.2, shuffle=True, scale_X=True, scale_t=True, random_state=SEED_VALUE)\n",
    "    model =  RidgeRegression(lambda_val=lmb)\n",
    "    z_hat_train = model.fit(X_train, z_train, SVDfit=False, keep_intercept=False)        \n",
    "    summary_df = model.summary()\n",
    "    summaries_df = pd.concat([summaries_df,summary_df], axis=0)\n",
    "    \n",
    "fig = plot_beta_errors_for_lambdas(summaries_df, optimal_degree)\n",
    "fig.savefig(f\"{REPORT_FIGURES}{EX6_4}Ridge_beta_SE_for_lambdas.pdf\")\n",
    "\n",
    "fig = plot_beta_CI_for_lambdas(summaries_df, optimal_degree)\n",
    "fig.savefig(f\"{REPORT_FIGURES}{EX6_4}Ridge_beta_CI_for_lambdas.pdf\")\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OLD code!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 - Finding optimal lambda for Ridge fit\n",
    "First we find the optimal value for the lambda parameter by splitting the input data into training and test data. Than we fit the model using different values for lambda. For each lambda value we use the mean square error on the test data evaluate how god the fit is. The best lambda value is used to fit a new model with all data (not using train-test split). <br>\n",
    "First we find the optimal parameter value of lambda, $\\lambda$, by evaluating overfit from evaluation plot where we plot the values for MSE for training and test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nbf_lambdas = 10\n",
    "lambdas = np.logspace(-5,5, nbf_lambdas)\n",
    "z_train_ridge = pd.DataFrame()\n",
    "z_hat_train_ridge = pd.DataFrame()\n",
    "z_test_ridge = pd.DataFrame()\n",
    "z_hat_test_ridge = pd.DataFrame()\n",
    "\n",
    "\n",
    "z_hat_train_ridge_sk = pd.DataFrame()\n",
    "z_hat_test_ridge_sk = pd.DataFrame()\n",
    "\n",
    "for lmb in lambdas:\n",
    "    model_sk = lm.Ridge(lmb, fit_intercept=False)\n",
    "    #X_train, X_test, z_train, z_test = prepare_data(X, z, test_size=0.2, shuffle=True, scale_X=False, scale_t=False)\n",
    "    X_train, X_test, z_train, z_test = prepare_data(X, z, test_size=0.2, shuffle=True, scale_X=False, scale_t=False, random_state=4155)\n",
    "    model = RidgeRegression(lmb) # The model\n",
    "    model.fit(X_train, z_train) # Fitting the model\n",
    "\n",
    "    # Fitting the scikit Ridge model\n",
    "    model_sk.fit(X_train, z_train)\n",
    "   \n",
    "    # Predictions our Ridge model\n",
    "    z_hat_train = model.predict(X_train) # predict on train data\n",
    "    z_hat_test = model.predict(X_test) # predict on test data\n",
    "\n",
    "    # Predictions sklearn Ridge\n",
    "    z_hat_train_sk = model_sk.predict(X_train) # predict on train data\n",
    "    z_hat_test_sk = model_sk.predict(X_test) # predict on test data\n",
    "\n",
    "    # Filling up dataframes\n",
    "    z_train_ridge[lmb] = z_train.flatten() \n",
    "    z_hat_train_ridge[lmb] = z_hat_train.flatten()\n",
    "    z_test_ridge[lmb] = z_test.flatten()\n",
    "    z_hat_test_ridge[lmb] = z_hat_test.flatten()\n",
    "\n",
    "    # Filling up sk dataframes\n",
    "    z_hat_train_ridge_sk[lmb] = z_hat_train_sk.flatten()\n",
    "    z_hat_test_ridge_sk[lmb] = z_hat_test_sk.flatten()\n",
    "\n",
    "\n",
    "# MSE calculations for all lambda values\n",
    "mse_scores_train = ((z_train_ridge - z_hat_train_ridge) ** 2).mean()\n",
    "mse_scores_test = ((z_test_ridge - z_hat_test_ridge) ** 2).mean()\n",
    "mse_scors_train_sk = ((z_train_ridge - z_hat_train_ridge_sk) ** 2).mean()\n",
    "mse_scores_test_sk = ((z_test_ridge - z_hat_test_ridge_sk) ** 2).mean()\n",
    "\n",
    "# R2 calculations for all lambda values\n",
    "R2_scores_train = 1 - ((z_train_ridge - z_hat_train_ridge) ** 2).sum() / ((z_train_ridge - z_train_ridge.mean())**2).sum() \n",
    "R2_scores_test = 1 - ((z_test_ridge - z_hat_test_ridge) ** 2).sum() / ((z_test_ridge - z_test_ridge.mean())**2).sum()  \n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(-np.log(lambdas), mse_scores_train, label=\"Training data\")\n",
    "plt.plot(-np.log(lambdas), mse_scores_test, label=\"Test data\")\n",
    "\n",
    "plt.plot(-np.log(lambdas), mse_scors_train_sk, 'm--', label=\"Training data sklearn\")\n",
    "plt.plot(-np.log(lambdas), mse_scores_test_sk, 'y--', label=\"Test data sklearn\")\n",
    "\n",
    "#plt.plot(mse_scores_train,-np.log(lambdas), label=\"Training data\")\n",
    "#plt.plot(mse_scores_test,-np.log(lambdas), label=\"Test data\")\n",
    "plt.xlabel(\"log(lambda)\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Training evaluation on Ridge regression fit\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{REPORT_FIGURES}franke_function_Ridge_evaluate_fit.pdf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform the same analysis as above, but with scaled data and fit intercept equal to false"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nbf_lambdas = 10\n",
    "lambdas = np.logspace(-5,5, nbf_lambdas)\n",
    "z_train_ridge = pd.DataFrame()\n",
    "z_hat_train_ridge = pd.DataFrame()\n",
    "z_test_ridge = pd.DataFrame()\n",
    "z_hat_test_ridge = pd.DataFrame()\n",
    "\n",
    "\n",
    "z_hat_train_ridge_sk = pd.DataFrame()\n",
    "z_hat_test_ridge_sk = pd.DataFrame()\n",
    "\n",
    "for lmb in lambdas:\n",
    "    model_sk = lm.Ridge(lmb, fit_intercept=False)\n",
    "    #X_train, X_test, z_train, z_test = prepare_data(X, z, test_size=0.2, shuffle=True, scale_X=False, scale_t=False)\n",
    "    X_train, X_test, z_train, z_test = prepare_data(X, z, test_size=0.2, shuffle=True, scale_X=False, scale_t=False, random_state=4155)\n",
    "    model = RidgeRegression(lmb) # The model\n",
    "    model.fit(X_train, z_train) # Fitting the model\n",
    "\n",
    "    # Fitting the scikit Ridge model\n",
    "    model_sk.fit(X_train, z_train)\n",
    "   \n",
    "    # Predictions our Ridge model\n",
    "    z_hat_train = model.predict(X_train) # predict on train data\n",
    "    z_hat_test = model.predict(X_test) # predict on test data\n",
    "\n",
    "    # Predictions sklearn Ridge\n",
    "    z_hat_train_sk = model_sk.predict(X_train) # predict on train data\n",
    "    z_hat_test_sk = model_sk.predict(X_test) # predict on test data\n",
    "\n",
    "    # Filling up dataframes\n",
    "    z_train_ridge[lmb] = z_train.flatten() \n",
    "    z_hat_train_ridge[lmb] = z_hat_train.flatten()\n",
    "    z_test_ridge[lmb] = z_test.flatten()\n",
    "    z_hat_test_ridge[lmb] = z_hat_test.flatten()\n",
    "\n",
    "    # Filling up sk dataframes\n",
    "    z_hat_train_ridge_sk[lmb] = z_hat_train_sk.flatten()\n",
    "    z_hat_test_ridge_sk[lmb] = z_hat_test_sk.flatten()\n",
    "\n",
    "\n",
    "# MSE calculations for all lambda values\n",
    "mse_scores_train = ((z_train_ridge - z_hat_train_ridge) ** 2).mean()\n",
    "mse_scores_test = ((z_test_ridge - z_hat_test_ridge) ** 2).mean()\n",
    "mse_scors_train_sk = ((z_train_ridge - z_hat_train_ridge_sk) ** 2).mean()\n",
    "mse_scores_test_sk = ((z_test_ridge - z_hat_test_ridge_sk) ** 2).mean()\n",
    "\n",
    "# R2 calculations for all lambda values\n",
    "R2_scores_train = 1 - ((z_train_ridge - z_hat_train_ridge) ** 2).sum() / ((z_train_ridge - z_train_ridge.mean())**2).sum() \n",
    "R2_scores_test = 1 - ((z_test_ridge - z_hat_test_ridge) ** 2).sum() / ((z_test_ridge - z_test_ridge.mean())**2).sum()  \n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(-np.log(lambdas), mse_scores_train, label=\"Training data\")\n",
    "plt.plot(-np.log(lambdas), mse_scores_test, label=\"Test data\")\n",
    "\n",
    "plt.plot(-np.log(lambdas), mse_scors_train_sk, 'm--', label=\"Training data sklearn\")\n",
    "plt.plot(-np.log(lambdas), mse_scores_test_sk, 'y--', label=\"Test data sklearn\")\n",
    "\n",
    "#plt.plot(mse_scores_train,-np.log(lambdas), label=\"Training data\")\n",
    "#plt.plot(mse_scores_test,-np.log(lambdas), label=\"Test data\")\n",
    "plt.xlabel(\"log(lambda)\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Training evaluation on Ridge regression fit\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{REPORT_FIGURES}franke_function_Ridge_evaluate_fit.pdf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.3.1\n",
    "Finding the optimal lambda by using the bootstrap resampling technique over different values of lamda. For each value of lambda, a bias-variance tradeoff chart as in exercise 2 is created. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_bootstraps = 100\n",
    "maxdegree = 12\n",
    "for lmb in lambdas:\n",
    "    MSE_test = np.zeros(maxdegree)\n",
    "    MSE_train = np.zeros(maxdegree)\n",
    "    polydegree = np.arange(maxdegree)\n",
    "    bias = np.zeros(maxdegree)\n",
    "    variance = np.zeros(maxdegree)\n",
    "\n",
    "    for degree in tqdm(range(maxdegree), desc = f\"Looping through polynomials up to {maxdegree} degrees with {n_bootstraps} bootstraps: \"):\n",
    "        model = RidgeRegression(lmb)\n",
    "        X = create_X(x, y, n=degree)\n",
    "        X_train, X_test, z_train, z_test = prepare_data(X, z)\n",
    "\n",
    "        # Reshape for broadcasting\n",
    "        z_test_ = np.reshape(z_test, newshape=(z_test.shape[0],1))\n",
    "        z_train_ = np.reshape(z_train, newshape=(z_train.shape[0],1))\n",
    "        \n",
    "        # Scaling data and preparing output arrays \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        #X_train_scaled = scaler.transform(X_train)\n",
    "        #X_test_scaled = scaler.transform(X_test)\n",
    "        z_pred = np.empty((z_test.shape[0], n_bootstraps))\n",
    "        z_fit = np.empty((z_train.shape[0], n_bootstraps))\n",
    "\n",
    "        # Bootstrapping\n",
    "        for i in range(n_bootstraps):\n",
    "            x_, z_ = resample(X_train, z_train)\n",
    "            model.fit(X_train, z_train)\n",
    "            z_pred[:,i] = model.predict(X_test)\n",
    "            z_fit[:,i] = model.predict(X_train)\n",
    "\n",
    "        MSE_test[degree] = np.mean( np.mean((z_test_ - z_pred)**2, axis=1, keepdims=True) )\n",
    "        MSE_train[degree] = np.mean( np.mean((z_train_ - z_fit)**2, axis=1, keepdims=True) )\n",
    "        bias[degree] = np.mean( (z_test - np.mean(z_pred, axis=1, keepdims=True))**2 )\n",
    "        variance[degree] = np.mean( np.var(z_pred, axis=1, keepdims=True))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(polydegree, MSE_test,\"m\", label='MSE\\_test')\n",
    "    plt.plot(polydegree, MSE_train,\"c\", label='MSE\\_train')\n",
    "\n",
    "    plt.plot(polydegree, bias,\"g--\", label='bias')\n",
    "    plt.plot(polydegree, variance,\"r--\", label='Variance')\n",
    "\n",
    "    plt.title(f\"Bias-Variance for log10(lambda) = {np.log10(lmb)}\")\n",
    "    plt.xlabel(\"Model complexity / Polynomial Degree\")\n",
    "    plt.ylabel(\"Prediction Error\")\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    display(model.summary())\n",
    "      \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4 Analysis of plots and training metrics\n",
    "Do the analysis.......\n",
    "\n",
    "Conclusion:<br>\n",
    "Based on the analysis, we conclude that a model complexity of degree 5 yields the most optimal fit."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.5 plot of the model using the most optimal parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scale = False\n",
    "\n",
    "if scale:\n",
    "    # Data Scalling\n",
    "    X_scaler = StandardScaler()\n",
    "    X_scaler.fit(X)\n",
    "    X_train = X_scaler.transform(X_train)\n",
    "    z_train = np.expand_dims(z,axis=1)  \n",
    "    z_scaler = StandardScaler()\n",
    "    z_scaler.fit(z_train)\n",
    "    z_train = z_scaler.transform(z_train)\n",
    "else:\n",
    "    X_train = X; z_train = z\n",
    "\n",
    "lam = -1.1\n",
    "model = RidgeRegression(lam) # The model\n",
    "model.fit(X_train, z_train) # Fitting the model\n",
    "z_hat = model.predict(X_train) # predict on train data\n",
    "\n",
    "# Evaluatation metrics\n",
    "# TODO:\n",
    "results_df = pd.DataFrame(columns=[\"MSE\", \"R2-score\"], index=[\"Training data\", \"Test data\"])\n",
    "results_df[\"MSE\"] = MSE(z, z_hat)\n",
    "results_df[\"R2-score\"] = R2(z, z_hat)\n",
    "results_df.to_csv(f\"{REPORT_DATA}redge_reg_lambda_{lam}.csv\")\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure()#figsize=(8,8))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.title.set_text(f\"Ridge regression fit to the Franke Function\\nDegree {degree},$\\lambda$:{lam}\")\n",
    "#ax.view_init(elev=5., azim=85.0)\n",
    "ax.view_init(elev=30., azim=-25.0)\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\n",
    "ax.scatter3D(x,y,z,c=z, cmap=cm.coolwarm, marker = '.')\n",
    "plt.savefig(f\"{REPORT_FIGURES}franke_function_Ridge_best_fit.pdf\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}