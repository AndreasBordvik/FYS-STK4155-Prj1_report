{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6: Analysis of real data  (score 30 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imageio import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import os\n",
    "from common import *\n",
    "import cv2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model as sk\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "#from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "print(f\"Root directory: {os.getcwd()}\")\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "    \"font.size\": 10,\n",
    "})\n",
    "\n",
    "#%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_VALUE = np.random.seed(4155)\n",
    " # Random seed to guarantee reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and plotting terrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the terrain\n",
    "terrain1_file = \"SRTM_data_Norway_1.tif\"\n",
    "terrain2_file = \"SRTM_data_Norway_2.tif\"\n",
    "terrain1 =  imread(f'{INPUT_DATA}{terrain1_file}')\n",
    "terrain2 = imread(f'{INPUT_DATA}{terrain2_file}')\n",
    "\n",
    "# Plotting terrain\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.title.set_text(\"Terrain over Norway 1\")\n",
    "ax1.set_xlabel(\"X\"); ax1.set_ylabel(\"Y\")\n",
    "surf1 = ax1.imshow(terrain1, cmap='gray')\n",
    "ax2.title.set_text(\"Terrain over Norway 2\")\n",
    "ax2.set_xlabel(\"X\"); ax2.set_ylabel(\"Y\")\n",
    "surf2 = ax2.imshow(terrain2, cmap='gray')\n",
    "plt.savefig(f\"{REPORT_FIGURES}{EX6}terrain_data.pdf\")\n",
    "plt.show()\n",
    "print(terrain1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts on the topographical data\n",
    "Before we proceed with this exercise, we want to briefly discuss the nature of this terrain data compared to the generated frank function. We regard the franke function as generic because it is known and its behavior or shape can be generated for other values of x and y. Thus, creating a model that can generalize the function even with added noise for other unknown data points for x and y makes sense. However, we are uncertain if this idea of generalization is transferable to topographical terrain data in the same sense. The terrain data given is unique, and its shape cannot be generalized for unknown data points. If the purpose is to create the absolute best fit for the specific and unique terrain data, one could simply overfit to the terrain data by having an extremely high degree when fitting a model, and that is not really ML. One could probably argue that a model should tackle added noise on the terrain data and still be able to represent the shapes and contours incorporated in the image. However, images are what they are, and in this case, the topographical terrain \"is what it is.\"  With that being said, we proceed with this exercise in the same spirit as done for exercises 1-5 even though we question this use case when working on this kind of real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0. Terrain data - Preprocessing and transformation\n",
    "Least Square regression is not designed to tackle images directly. Thus, we must first transform the terrain data by slicing it into several bits and pieces. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0.1 Resizeing the terrain image\n",
    "For computational purpose, we resize the terrain image to have a resonable amount of datapoints for our least sqaure models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale_factor = 0.1\n",
    "ySize = int(terrain1.shape[0] * rescale_factor); print(ySize)\n",
    "xSize = int(terrain1.shape[1] * rescale_factor); print(xSize)\n",
    "terrain1Resized = cv2.resize(terrain1, (xSize, ySize))\n",
    "terrain2Resized = cv2.resize(terrain2, (xSize, ySize))\n",
    "\n",
    "# Plotting terrain\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.title.set_text(\"Terrain over Norway 1 (Resized)\")\n",
    "ax1.set_xlabel(\"X\"); ax1.set_ylabel(\"Y\")\n",
    "surf1 = ax1.imshow(terrain1Resized, cmap='gray')\n",
    "ax2.title.set_text(\"Terrain over Norway 2 (Resized)\")\n",
    "ax2.set_xlabel(\"X\"); ax2.set_ylabel(\"Y\")\n",
    "surf2 = ax2.imshow(terrain2Resized, cmap='gray')\n",
    "plt.savefig(f\"{REPORT_FIGURES}{EX6}terrain_data_resized.pdf\")\n",
    "plt.show()\n",
    "print(terrain1[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0.2 Creating image patches and Terrain data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img_patches(img, ySteps, xSteps):\n",
    "    patches = []\n",
    "    for y in range(0,img.shape[0], ySteps):\n",
    "        for x in range(0,img.shape[1], xSteps):\n",
    "            y_from = y; \n",
    "            y_to = y+ySteps; \n",
    "            x_from = x; \n",
    "            x_to = x+xSteps; \n",
    "            img_patch = img[y_from:y_to, x_from:x_to]        \n",
    "            patches.append(img_patch)\n",
    "\n",
    "    return patches\n",
    "\n",
    "def patches_to_img(patches, ySteps, xSteps, nYpatches, nXpatches, plotImage=False):\n",
    "    img = np.zeros((ySteps*nYpatches, xSteps*nXpatches))\n",
    "    i = 0\n",
    "    for y in range(0,img.shape[0], ySteps):\n",
    "        for x in range(0,img.shape[1], xSteps):\n",
    "            y_from = y; \n",
    "            y_to = y+ySteps; \n",
    "            x_from = x; \n",
    "            x_to = x+xSteps; \n",
    "            img[y_from:y_to, x_from:x_to] = patches[i]         \n",
    "            i += 1\n",
    "    \n",
    "    if plotImage:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(\"Reconstructed img\")\n",
    "        plt.show()\n",
    "    return img\n",
    "\n",
    "def plotTerrainPatches(patches, nYpatches, nXpatches, plotTitle=\"Terrain patches\"):\n",
    "    # Plotting terrain patches\n",
    "    fig, ax = plt.subplots(nYpatches, nXpatches,figsize=(4,10))\n",
    "    i=0\n",
    "    for y in range(nYpatches):\n",
    "        for x in range(nXpatches):\n",
    "            ax[y,x].title.set_text(f\"Patch{i}\")\n",
    "            ax[y,x].set_xlabel(\"X\"); ax1.set_ylabel(\"Y\")\n",
    "            ax[y,x].imshow(patches[i], cmap='gray')\n",
    "            i+=1\n",
    "    \n",
    "    fig.suptitle(f\"{plotTitle}\") # or plt.suptitle('Main title')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{REPORT_FIGURES}{EX6}{plotTitle}.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "def createTerrainData(terrain, includeMeshgrid=True):\n",
    "    z = np.array(terrain) \n",
    "    x = np.arange(0, z.shape[1])\n",
    "    y = np.arange(0, z.shape[0])\n",
    "    if includeMeshgrid:\n",
    "        x, y = np.meshgrid(x,y)\n",
    "    return x,y,z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nXpatches = 3; nYpatches=6\n",
    "y_steps = int(terrain2Resized.shape[0] / nYpatches); print(y_steps)\n",
    "x_steps = int(terrain2Resized.shape[1] / nXpatches); print(x_steps)\n",
    "\n",
    "patches_1 = create_img_patches(terrain1Resized, y_steps, x_steps)\n",
    "plotTerrainPatches(patches_1, nYpatches, nXpatches, plotTitle=\"Terrain1 patches\")\n",
    "\n",
    "patches_2 = create_img_patches(terrain2Resized, y_steps, x_steps)\n",
    "plotTerrainPatches(patches_2, nYpatches, nXpatches, plotTitle=\"Terrain2 patches\")\n",
    "\n",
    "# test\n",
    "#img_reconstructed = patches_to_img(patches, y_steps, x_steps, nYpatches, nXpatches, plotImage=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0.3 Choosing of terrain patch and data creation\n",
    "We look at the terrain data patches and choose which to create a fit for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = patches_1[2]\n",
    "img2 = patches_2[5]\n",
    "x1, y1, z1 = createTerrainData(img1)\n",
    "x2, y2, z2 = createTerrainData(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = MinMaxScaler()\n",
    "scaler1.fit(img1)\n",
    "img1_normalized = scaler1.transform(img1)\n",
    "norm_var1 = np.round(np.var(img1_normalized),decimals=4)\n",
    "\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler2.fit(img2)\n",
    "img2_normalized = scaler1.transform(img2)\n",
    "norm_var2 = np.round(np.var(img2_normalized),decimals=4)\n",
    "\n",
    "# 2D plot of the terrain patches\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.title.set_text(f\"Terrain patch from terrain1\\nMean:\\\n",
    "{np.round(np.mean(img1),decimals=1)}\\nVariance: {np.round(np.var(img1),decimals=1)}\\n\\\n",
    "normalized variance: {norm_var1}\")\n",
    "ax1.set_xlabel(\"X\"); ax1.set_ylabel(\"Y\")\n",
    "surf1 = ax1.imshow(img1, cmap='gray')\n",
    "\n",
    "ax2.title.set_text(F\"Terrain patch from terrain2\\nMean:\\\n",
    "{np.round(np.mean(img2),decimals=1)}\\nVariance: {np.round(np.var(img2),decimals=1)}\\n\\\n",
    "normalized variance: {norm_var2}\")\n",
    "ax2.set_xlabel(\"X\"); ax2.set_ylabel(\"Y\")\n",
    "surf2 = ax2.imshow(img2, cmap='gray')\n",
    "plt.savefig(f\"{REPORT_FIGURES}{EX6}terrain_patch_to_fit_2D.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# 3D plot of the terrain patches\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,2,1, projection='3d')\n",
    "ax1.title.set_text(f\"3D plot of terrain1 patch\")\n",
    "ax1.set_xlabel(\"x\"); ax1.set_ylabel(\"y\"); ax1.set_zlabel(\"z\")\n",
    "#ax1.view_init(elev=60., azim=-120.0-70)\n",
    "#ax1.view_init(elev=-60., azim=-120.0+30)\n",
    "ax1.view_init(elev=-75., azim=-91)\n",
    "ax1.plot_surface(x1, y1, z1, cmap=cm.coolwarm, linewidth = 0, antialiased=False)\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2, projection='3d')\n",
    "ax2.title.set_text(\"3D plot of terrain2 patch\")\n",
    "ax2.set_xlabel(\"x\"); ax2.set_ylabel(\"y\"); ax2.set_zlabel(\"z\")\n",
    "#ax2.view_init(elev=60., azim=-120.0)\n",
    "ax2.view_init(elev=-45., azim=-85.0)\n",
    "ax2.plot_surface(x2, y2, z2, cmap=cm.coolwarm, linewidth = 0, antialiased=False)\n",
    "plt.savefig(f\"{REPORT_FIGURES}{EX6}terrain_patch_to_fit_3D.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0.4 Base input data for all exercises\n",
    "We construct the data for least square regression based on preprocessed data. We also set up variables that will be used throughout the exercise.<br>\n",
    "Terrain patch from terrain 1 is used as input for our models and our tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain_data = 1\n",
    "\n",
    "if terrain_data == 1: # Choosing terrain1*\n",
    "    x, y, z = x1, y1, z1.copy() \n",
    "    #z_min = np.min(z)\n",
    "    z_max = np.max(z)\n",
    "    z = z1\n",
    "\n",
    "elif terrain_data == 2: # Choosing terrain2\n",
    "    x, y, z = x2, y2, z2.copy() \n",
    "    #z_min = np.min(z)\n",
    "    z_max = np.max(z)\n",
    "    z = z2\n",
    "    \n",
    "z_flat = z.ravel(); z_flat = z_flat.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 OLS on data (Exercise1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running OLS fit on the data as done in EX1 \n",
    "Note that we exlude the calculation of CL for betas, since it is emedded within the model itself. See common.py for that code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train_OLS = pd.DataFrame()\n",
    "z_hat_train_OLS = pd.DataFrame()\n",
    "z_test_OLS = pd.DataFrame()\n",
    "z_hat_test_OLS = pd.DataFrame()\n",
    "X_test_OLS = {}\n",
    "df = pd.DataFrame()\n",
    "\n",
    "degrees = 44\n",
    "scale_X = True\n",
    "scale_z = True\n",
    "test_size = 0.2\n",
    "fitted_models = []\n",
    "for degree in range(1, degrees+1):\n",
    "    print(f\"Running OLS fitting on degree{degree}\")\n",
    "    X = create_X(x, y, degree) # Design Matrix\n",
    "\n",
    "    # Scaling data and splitting it into training and test sets\n",
    "    if scale_X:\n",
    "        if scale_z:\n",
    "            X_train, X_test, z_train, z_test = prepare_data(X, z_flat, test_size=test_size, shuffle=True, scale_X=True, scale_t=True, random_state=SEED_VALUE)\n",
    "        else:\n",
    "            X_train, X_test, z_train, z_test = prepare_data(X, z_flat, test_size=test_size, shuffle=True, scale_X=True, scale_t=False, random_state=SEED_VALUE)\n",
    "    else:\n",
    "         X_train, X_test, z_train, z_test = prepare_data(X, z_flat, test_size=test_size, shuffle=True, scale_X=False, scale_t=False, random_state=SEED_VALUE)\n",
    "    \n",
    "    #print(X_train[:, 0:1])\n",
    "    # Model construction, fitting, and predictions\n",
    "    model = OLS(degree=degree) # The model\n",
    "    z_hat_train = model.fit(X_train, z_train) # Fitting the model and predict on training data\n",
    "    z_hat_test = model.predict(X_test) # predict on test data\n",
    "    \n",
    "    # Evaluatation metrics\n",
    "    #MSE_score_train = MSE(z_train, z_hat_train)\n",
    "    #R2_score_train = R2(z_train, z_hat_train)\n",
    "    #MSE_score_test = MSE(z_test, z_hat_test)\n",
    "    #R2_score_test = R2(z_test, z_hat_test)\n",
    "            \n",
    "    # Filling up dataframes for train and test evaluation\n",
    "    summary_df = model.summary()\n",
    "    df = pd.concat([df,summary_df], axis=0)\n",
    "\n",
    "    z_train_OLS[degree] = z_train.flatten()\n",
    "    z_hat_train_OLS[degree] = z_hat_train.flatten()\n",
    "    z_test_OLS[degree] = z_test.flatten()\n",
    "    z_hat_test_OLS[degree] = z_hat_test.flatten()\n",
    "    X_test_OLS[f\"{degree}\"] = X_test\n",
    "\n",
    "    # Storing data for all degrees\n",
    "    results = {\"X_train\":X_train, \"X_test\":X_test,\"z_train\":z_train, \"z_test\":z_test,\n",
    "               \"z_hat_train\":z_hat_train, \"z_hat_test\":z_hat_test, \"model\":model, \"summary\":summary_df}\n",
    "    #OLSrun.append(results)\n",
    "    fitted_models.append(model)\n",
    "\n",
    "# MSE calculations for all degrees\n",
    "mse_scores_train = ((z_train_OLS - z_hat_train_OLS) ** 2).mean()\n",
    "mse_scores_test = ((z_test_OLS - z_hat_test_OLS) ** 2).mean()\n",
    "# R2 calculations for all degrees\n",
    "R2_scores_train = 1 - ((z_train_OLS - z_hat_train_OLS) ** 2).sum() / ((z_train_OLS - z_train_OLS.mean())**2).sum() \n",
    "R2_scores_test = 1 - ((z_test_OLS - z_hat_test_OLS) ** 2).sum() / ((z_test_OLS - z_test_OLS.mean())**2).sum()\n",
    "\n",
    "# Plotting performance of OLS for different degrees\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(np.arange(1,degrees+1), mse_scores_test,\"m\", label=f'MSE on test (test fraction:{test_size})')\n",
    "plt.plot(np.arange(1,degrees+1), mse_scores_train,\"c\", label='MSE on train')\n",
    "plt.plot(np.arange(1,degrees+1), R2_scores_test, label=f'R2 on test (test fraction:{test_size})')\n",
    "plt.plot(np.arange(1,degrees+1), R2_scores_train, label='R2 on train')\n",
    "plt.xlabel(\"Model complexity / Polynomial Degree\")\n",
    "plt.ylabel(\"Prediction Error - MSE\")\n",
    "plt.xticks(np.arange(1,degrees+1))\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title(\"Exercise 6.1 - Model evaluation\")\n",
    "plt.savefig(f\"{REPORT_FIGURES}{EX6_1}OLS_evaluattion.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at $\\beta$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_degree = 5\n",
    "df_degree = df[df[\"degree\"] == optimal_degree]\n",
    "print(\"df_degree.shape:\",df_degree.shape)\n",
    "display(df_degree)\n",
    "df_degree.to_csv(f\"{REPORT_DATA}{EX6_1}OLS_beta_error_degree{optimal_degree}.csv\")\n",
    "\n",
    "fig = plot_beta_errors(df_degree, optimal_degree)\n",
    "fig.savefig(f\"{REPORT_FIGURES}{EX6_1}OLS_beta_error_degree{optimal_degree}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting predicted terrain using fitted degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees_insight = [4,5,17]\n",
    "z_hats = [z]\n",
    "for deg in degrees_insight:\n",
    "    X = create_X(x, y, deg) # Design Matrix \n",
    "    X = remove_intercept(X)\n",
    "    X_scaled, _ = standard_scaling_single(X)\n",
    "    z_scaled, z_scaler = standard_scaling_single(z.ravel().reshape(-1,1))\n",
    "         \n",
    "    # Using fitted model to predict the terrain patch \n",
    "    model = fitted_models[deg-1]\n",
    "    z_hat = model.predict(X_scaled)\n",
    "\n",
    "    z_hat = z_scaler.inverse_transform(z_hat.reshape(-1,1))\n",
    "    #print(z_hat.shape)\n",
    "    z_hat = z_hat.reshape((y_steps,x_steps))\n",
    "    z_hats.append(z_hat)\n",
    "z_hats = np.array(z_hats)\n",
    "\n",
    "# 2D plot of predicted terrain patches\n",
    "fig = plt.figure(figsize=(7,16))\n",
    "j = 0\n",
    "for i in range(z_hats.shape[0]):\n",
    "    ax = fig.add_subplot(z_hats.shape[0],2,1+i)\n",
    "    title = f\"Predicted terrain\\n(OLS degree {degrees_insight[j]})\" if i>0 else \"Target terrain\"\n",
    "    ax.title.set_text(f\"{title}\\nMean:\\\n",
    "    {np.round(np.mean(z_hats[i]),decimals=1)}\\nVariance: {np.round(np.var(z_hats[i]),decimals=1)}\")\n",
    "    \n",
    "    ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\")\n",
    "    surf2 = ax.imshow(z_hats[i], cmap='gray')\n",
    "    j+=1 if i > 0 else j\n",
    "\n",
    "plt.suptitle(\"Exercise 6.1 - 2D plot of Terrain\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{REPORT_FIGURES}{EX6_1}target_terrain_and_OLS_prediction_2D.pdf\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 3D plot of predicted terrain patches\n",
    "fig = plt.figure(figsize=(7,16))\n",
    "j = 0\n",
    "for i in range(z_hats.shape[0]):\n",
    "    ax = fig.add_subplot(z_hats.shape[0],2,1+i, projection='3d')\n",
    "    title = f\"Predicted terrain\\n(OLS degree {degrees_insight[j]})\" if i>0 else \"Target terrain\"\n",
    "    ax.title.set_text(title)\n",
    "    ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\n",
    "    #ax2.view_init(elev=60., azim=-120.0-70)\n",
    "    ax.view_init(elev=-75., azim=-91)\n",
    "    ax.plot_surface(x, y, z_hats[i], cmap=cm.coolwarm, linewidth = 0, antialiased=False)\n",
    "    j+=1 if i > 0 else j\n",
    "\n",
    "plt.suptitle(\"Exercise 6.1 - 3D plot of Terrain\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{REPORT_FIGURES}{EX6_1}target_terrain_and_OLS_prediction_3D.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments on the OLS fit to terrain data:\n",
    "We scale the data since x, y, z is they are not between 0 to 1. Degree of 4 seems to yeild the best performance when fitting to the choosen terrain data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "#### This text may have to be adjusted\n",
    "A degree of 4 or 5 seems to give a smooth surface for all the predicted patches. We find that the distortion and noise increase in the predicted image when the degree increases above 4-5 considering all patches. At higher degrees, some artifacts within the predicted patches also appear. In the predicted image with all patches, one can see some of the contours of the topographic structures in the image we try to approximate. However, the predicted image that is reconstructed from all the predicted patches is not very accurate. The task of this kind of problem is too complex for an OLS to manage. It may be that having smaller patches would increase the accuracy in reproducing the details incorporated in the input image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Bias-variance trade-off and resampling techniques on terrain data (Exercise2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.1 Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 Cross-validation as resampling techniques, adding more complexity (Exercise3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.1 Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree in range(1,20):\n",
    "    X = create_X(x,y,degree)\n",
    "    #remove intercept: \n",
    "    X = X[:,1:]\n",
    "\n",
    "\n",
    "    mean_folds_error = np.zeros(6)\n",
    "    mean_folds_error_sk = np.zeros(6)\n",
    "\n",
    "    mse_std_arr = np.zeros(6)\n",
    "    for folds in range(5,11):\n",
    "        \n",
    "\n",
    "        implemented_scores = cross_val_ex6(k = folds, model = \"OLS\", X = X, z = z, degree=degree, shuffle=True)\n",
    "        mean_folds_error[folds-5] = np.mean(implemented_scores)\n",
    "        mse_std_arr[folds-5] = np.std(implemented_scores)\n",
    "\n",
    "    plt.plot(np.arange(5,11), mean_folds_error, \"o--\",  label = \"Mean MSE CV\")\n",
    "    plt.fill_between(np.arange(5,11), mean_folds_error-mse_std_arr, mean_folds_error+mse_std_arr,  alpha = 0.2)\n",
    "    plt.title(f\"Model complexity: {degree} degrees\")\n",
    "    plt.xlabel(\"K-fold\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    #plt.ylim(0,2)\n",
    "    plt.xticks(np.arange(5,11))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{REPORT_FIGURES}{EX6}mse_cv_boot{degree}.pdf\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4 Ridge Regression on the Franke function with resampling (Exercise4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.1 Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": []
=======
   "source": [
    "#np.random.seed(4155)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "degree = 8\n",
    "min_lambda = -9\n",
    "max_lambda = 4\n",
    "nlambdas = 500\n",
    "lambdas = np.logspace(min_lambda,max_lambda, nlambdas)\n",
    "\n",
    "z_train_OLS = pd.DataFrame()\n",
    "z_hat_train_OLS = pd.DataFrame()\n",
    "z_test_OLS = pd.DataFrame()\n",
    "z_hat_test_OLS = pd.DataFrame()\n",
    "\n",
    "X = create_X(x,y,degree)\n",
    "X_train, X_test, t_train, t_test = prepare_data(X,z_flat, 4155, scale_X=True, scale_t=True)\n",
    "\n",
    "MSERidgePredict = np.zeros(nlambdas)\n",
    "MSEOurRidge = np.zeros(nlambdas)\n",
    "MSEsklearn = np.zeros(nlambdas)\n",
    "lambdas = np.logspace(min_lambda, max_lambda, nlambdas)\n",
    "for i in range(nlambdas):\n",
    "    lmb = lambdas[i]\n",
    "\n",
    "    # our Ridge\n",
    "    model = RidgeRegression(lmb)\n",
    "    z_hat_train = model.fit(X_train, t_train)\n",
    "    z_hat_test = model.predict(X_test)\n",
    "    MSEOurRidge[i] = MSE(t_test, z_hat_test)\n",
    "    MSEsklearn[i] = mean_squared_error(t_test, z_hat_test)\n",
    "\n",
    "    summary_df = model.summary()\n",
    "    df = pd.concat([df,summary_df], axis=0)\n",
    "\n",
    "    z_train_OLS[i] = z_train.flatten()\n",
    "    z_hat_train_OLS[i] = z_hat_train.flatten()\n",
    "    z_test_OLS[i] = z_test.flatten()\n",
    "    z_hat_test_OLS[i] = z_hat_test.flatten()\n",
    "\n",
    "    # Storing data for all degrees\n",
    "    results = {\"X_train\":X_train, \"X_test\":X_test,\"z_train\":z_train, \"z_test\":z_test,\n",
    "               \"z_hat_train\":z_hat_train, \"z_hat_test\":z_hat_test, \"model\":model, \"summary\":summary_df}\n",
    "\n",
    "# MSE calculations for all lambdas\n",
    "#mse_scores_train = ((z_train_OLS - z_hat_train_OLS) ** 2).mean()\n",
    "#mse_scores_test = ((z_test_OLS - z_hat_test_OLS) ** 2).mean()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.log10(lambdas), MSEsklearn, 'm', label = \"MSE Ridge\")\n",
    "plt.xlabel('log10(lambda)')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
>>>>>>> 0d6284bcba8396f0cb69cd0326e3c1447badf6d1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5. Lasso Regression on the Franke function with resampling (Exercise5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5.1 Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.6 Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is used to evaluate best degree for all patches\n",
    "n_xpatches = 9; n_ypatches=18\n",
    "y_steps = int(terrain1Resized.shape[0] / n_ypatches); print(y_steps)\n",
    "x_steps = int(terrain1Resized.shape[1] / n_xpatches); print(x_steps)\n",
    "\n",
    "patches_1_test = create_img_patches(terrain1Resized, y_steps, x_steps)\n",
    "#plotTerrainPatches(patches_1_test, n_ypatches, n_xpatches, plotTitle=\"Terrain1 patches\")\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(SEED_VALUE) \n",
    "z_flat = z.ravel(); z_flat = z_flat.reshape(-1,1)\n",
    "z_train_OLS = pd.DataFrame()\n",
    "z_hat_train_OLS = pd.DataFrame()\n",
    "z_test_OLS = pd.DataFrame()\n",
    "z_hat_test_OLS = pd.DataFrame()\n",
    "X_test_OLS = {}\n",
    "df = pd.DataFrame()\n",
    "\n",
    "degrees = 22\n",
    "scale_X = True\n",
    "scale_z = True\n",
    "test_size = 0.2\n",
    "fitted_models = []\n",
    "plot = False\n",
    "for patch in patches_1_test:\n",
    "    for degree in range(1, degrees+1):\n",
    "        #print(f\"Running OLS fitting on degree{degree}\")\n",
    "        xpatch, ypatch, zpatch = createTerrainData(patch)\n",
    "        zpatch = zpatch.ravel().reshape(-1,1)\n",
    "\n",
    "        X = create_X(xpatch, ypatch, degree) # Design Matrix\n",
    "\n",
    "        # Scaling data and splitting it into training and test sets\n",
    "        if scale_X:\n",
    "            if scale_z:\n",
    "                X_train, X_test, z_train, z_test = prepare_data(X, zpatch, test_size=test_size, shuffle=True, scale_X=True, scale_t=True, random_state=SEED_VALUE)\n",
    "            else:\n",
    "                X_train, X_test, z_train, z_test = prepare_data(X, zpatch, test_size=test_size, shuffle=True, scale_X=True, scale_t=False, random_state=SEED_VALUE)\n",
    "        else:\n",
    "            X_train, X_test, z_train, z_test = prepare_data(X, zpatch, test_size=test_size, shuffle=True, scale_X=False, scale_t=False, random_state=SEED_VALUE)\n",
    "        \n",
    "        #print(X_train[:, 0:1])\n",
    "        # Model construction, fitting, and predictions\n",
    "        model = OLS(degree=degree) # The model\n",
    "        z_hat_train = model.fit(X_train, z_train) # Fitting the model and predict on training data\n",
    "        z_hat_test = model.predict(X_test) # predict on test data\n",
    "        \n",
    "        # Evaluatation metrics\n",
    "        MSE_score_train = MSE(z_train, z_hat_train)\n",
    "        R2_score_train = R2(z_train, z_hat_train)\n",
    "        MSE_score_test = MSE(z_test, z_hat_test)\n",
    "        R2_score_test = R2(z_test, z_hat_test)\n",
    "                \n",
    "        # Filling up dataframes for train and test evaluation\n",
    "        z_train_OLS[degree] = z_train.flatten()\n",
    "        z_hat_train_OLS[degree] = z_hat_train.flatten()\n",
    "        z_test_OLS[degree] = z_test.flatten()\n",
    "        z_hat_test_OLS[degree] = z_hat_test.flatten()\n",
    "        X_test_OLS[f\"{degree}\"] = X_test\n",
    "\n",
    "   \n",
    "        fitted_models.append(model)\n",
    "\n",
    "    # MSE calculations for all degrees\n",
    "    mse_scores_train = ((z_train_OLS - z_hat_train_OLS) ** 2).mean()\n",
    "    mse_scores_test = ((z_test_OLS - z_hat_test_OLS) ** 2).mean()\n",
    "    # R2 calculations for all degrees\n",
    "    R2_scores_train = 1 - ((z_train_OLS - z_hat_train_OLS) ** 2).sum() / ((z_train_OLS - z_train_OLS.mean())**2).sum() \n",
    "    R2_scores_test = 1 - ((z_test_OLS - z_hat_test_OLS) ** 2).sum() / ((z_test_OLS - z_test_OLS.mean())**2).sum()\n",
    "\n",
    "    # Plotting performance of OLS for different degrees\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(np.arange(1,degrees+1), mse_scores_test,\"m\", label=f'MSE on test (test fraction:{test_size})')\n",
    "        plt.plot(np.arange(1,degrees+1), mse_scores_train,\"c\", label='MSE on train')\n",
    "        # plt.plot(np.arange(1,degrees+1), R2_scores_test, label=f'R2 on test (test fraction:{test_size})')\n",
    "        # plt.plot(np.arange(1,degrees+1), R2_scores_train, label='R2 on train')\n",
    "        plt.xlabel(\"Model complexity / Polynomial Degree\")\n",
    "        plt.ylabel(\"Prediction Error - MSE\")\n",
    "        plt.xticks(np.arange(1,degrees+1))\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.title(\"Exercise 6.1 - Model evaluation\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS fit on the whole terrain1 data\n",
    "Using degree 8 for all models for alle patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_xpatches = 9; n_ypatches=18\n",
    "y_steps = int(terrain1Resized.shape[0] / n_ypatches); print(y_steps)\n",
    "x_steps = int(terrain1Resized.shape[1] / n_xpatches); print(x_steps)\n",
    "\n",
    "patches_1_test = create_img_patches(terrain1Resized, y_steps, x_steps)\n",
    "#plotTerrainPatches(patches_1_test, n_ypatches, n_xpatches, plotTitle=\"Terrain1 patches\")\n",
    "\n",
    "np.random.seed(SEED_VALUE) \n",
    "z_flat = z.ravel(); z_flat = z_flat.reshape(-1,1)\n",
    "z_train_OLS = pd.DataFrame()\n",
    "z_hat_train_OLS = pd.DataFrame()\n",
    "z_test_OLS = pd.DataFrame()\n",
    "z_hat_test_OLS = pd.DataFrame()\n",
    "X_test_OLS = {}\n",
    "df = pd.DataFrame()\n",
    "\n",
    "degree = 8\n",
    "\n",
    "# Fitting the model \n",
    "scale_X = True\n",
    "scale_z = True\n",
    "test_size = 0.2\n",
    "fitted_models = []\n",
    "for patch in patches_1_test:\n",
    "    xpatch, ypatch, zpatch = createTerrainData(patch)\n",
    "    zpatch = zpatch.ravel().reshape(-1,1)\n",
    "    X = create_X(xpatch, ypatch, degree) # Design Matrix\n",
    "\n",
    "    # Scaling data and splitting it into training and test sets\n",
    "    if scale_X:\n",
    "        if scale_z:\n",
    "            X_train, X_test, z_train, z_test = prepare_data(X, zpatch, test_size=test_size, shuffle=True, scale_X=True, scale_t=True, random_state=SEED_VALUE)\n",
    "        else:\n",
    "            X_train, X_test, z_train, z_test = prepare_data(X, zpatch, test_size=test_size, shuffle=True, scale_X=True, scale_t=False, random_state=SEED_VALUE)\n",
    "    else:\n",
    "        X_train, X_test, z_train, z_test = prepare_data(X, zpatch, test_size=test_size, shuffle=True, scale_X=False, scale_t=False, random_state=SEED_VALUE)\n",
    "    \n",
    "    #print(X_train[:, 0:1])\n",
    "    # Model construction, fitting, and predictions\n",
    "    model = OLS(degree=degree) # The model\n",
    "    z_hat_train = model.fit(X_train, z_train) # Fitting the model and predict on training data\n",
    "    fitted_models.append(model)\n",
    "    \n",
    "\n",
    "# prediction patches\n",
    "z_hats = []\n",
    "for i, patch in enumerate(patches_1_test):\n",
    "    #z_scaled, _ = standard_scaling_single(patch.ravel().reshape(-1,1))\n",
    "    xpatch, ypatch, zpatch = createTerrainData(patch)\n",
    "    X = create_X(xpatch, ypatch, degree) # Design Matrix\n",
    "    X = remove_intercept(X)\n",
    "    X_scaled, _ = standard_scaling_single(X)\n",
    "    model = fitted_models[i]\n",
    "    z_hat = model.predict(X_scaled)\n",
    "    z_hats.append(z_hat.reshape((y_steps,x_steps)))\n",
    "\n",
    "    \n",
    "terrain1_predicted = patches_to_img(z_hats, y_steps, x_steps, n_ypatches, n_xpatches, plotImage=False)\n",
    "\n",
    "# Plotting predicted patches\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.title.set_text(f\"Terrain1 (resized)\")\n",
    "ax1.set_xlabel(\"X\"); ax1.set_ylabel(\"Y\")\n",
    "surf1 = ax1.imshow(terrain1Resized, cmap='gray')\n",
    "ax2.title.set_text(f\"Terrain1 - OLS predicted\")\n",
    "ax2.set_xlabel(\"X\"); ax2.set_ylabel(\"Y\")\n",
    "surf2 = ax2.imshow(terrain1_predicted, cmap='gray')\n",
    "plt.savefig(f\"{REPORT_FIGURES}{EX6}terrain_OLS_pred_all_patches_at_degree{degree}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to overfit to terrain for all patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testDegree = 150\n",
    "testDegree = 10\n",
    "patches_1_preds = []\n",
    "X = create_X(x1, y1, testDegree) # Design Matrix\n",
    "X_scaled, _ = standard_scaling_single(X)\n",
    "\n",
    "for patch in tqdm(patches_1_test):\n",
    "    z_scaled, _ = standard_scaling_single(patch.ravel().reshape(-1,1))\n",
    "    model = OLS(degree=testDegree) # The model\n",
    "    z_hat_train = model.fit(X_scaled, z_scaled) # Fitting the model and predict on training data\n",
    "    z_hat = z_hat_train.reshape((y_steps,x_steps))\n",
    "    patches_1_preds.append(z_hat)\n",
    "    \n",
    "terrain1_predicted = patches_to_img(patches_1_preds, y_steps, x_steps, nYpatches, nXpatches, plotImage=False)\n",
    "\n",
    "# Plotting predicted patches\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.title.set_text(f\"Terrain1 (resized)\")\n",
    "ax1.set_xlabel(\"X\"); ax1.set_ylabel(\"Y\")\n",
    "surf1 = ax1.imshow(terrain1Resized, cmap='gray')\n",
    "ax2.title.set_text(f\"Terrain1 - OLS predicted\")\n",
    "ax2.set_xlabel(\"X\"); ax2.set_ylabel(\"Y\")\n",
    "surf2 = ax2.imshow(terrain1_predicted, cmap='gray')\n",
    "plt.savefig(f\"{REPORT_FIGURES}{EX6_1}terrain_and_all_patches_predicted_at_degree{testDegree}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests of dimensions image reduction and patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "value = 180\n",
    "while True:\n",
    "    i += 1\n",
    "    if((value % i)==0):\n",
    "        print(f\"value:{value / i} at i:{i}\")\n",
    "    if(i>=value):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "value = 360\n",
    "while True:\n",
    "    i += 1\n",
    "    if((value % i)==0):\n",
    "        print(f\"value:{value / i} at i:{i}\")\n",
    "    if(i>=value):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c543d25d076d866156e6f2c445c66d614286218a5e81464998dcfdeffc50581"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
