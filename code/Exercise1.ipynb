{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import os\r\n",
    "from common import *\r\n",
    "import pandas as pd\r\n",
    "#from mpl_toolkits.mplot3d import Axes3D\r\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\r\n",
    "\r\n",
    "os.chdir(\"../\")\r\n",
    "print(f\"Root directory: {os.getcwd()}\")\r\n",
    "\r\n",
    "plt.rcParams.update({\r\n",
    "    \"text.usetex\": True,\r\n",
    "    \"font.family\": \"serif\",\r\n",
    "    \"font.serif\": [\"Palatino\"],\r\n",
    "    \"font.size\": 10,\r\n",
    "})\r\n",
    "\r\n",
    "%matplotlib inline "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Root directory: c:\\Users\\andre\\Dropbox\\FYS-STK4155_projects\\FYS-STK4155 - Project1\\FYS-STK4155-Prj1_report\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Global variables "
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "INPUT_DATA = \"data/input_data/\"  # Path for input data\r\n",
    "REPORT_DATA = \"data/report_data/\" # Path for data ment for the report\r\n",
    "REPORT_FIGURES = \"figures/\" # Path for figures ment for the report"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Franke function 3D preview\r\n",
    "First we plot a 3D plot of the franke function.\r\n",
    "The plot is based on the provided code in the assignmentext for plotting the franke function "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Preview plot of the franke function\r\n",
    "%matplotlib\r\n",
    "np.random.seed(4155)\r\n",
    "y = x = np.arange(0, 1, 0.05)\r\n",
    "x, y = np.meshgrid(x,y)\r\n",
    "z = FrankeFunction(x, y)\r\n",
    "noise_mesh = 0.05 * np.random.randn(z.shape[0], z.shape[1]) # Stochastic noise\r\n",
    "z_noisy = z + noise_mesh\r\n",
    "\r\n",
    "fig = plt.figure()\r\n",
    "# Ploting frankefunction without noise\r\n",
    "ax1 = fig.add_subplot(1,2,1, projection='3d') # Are :)steike\r\n",
    "ax1.title.set_text(\"Plot of the Franke Function\")\r\n",
    "ax1.view_init(elev=30., azim=-25.0)\r\n",
    "ax1.set_xlabel(\"x\"); ax1.set_ylabel(\"y\"); ax1.set_zlabel(\"z\")\r\n",
    "surf1 = ax1.plot_surface(x,y,z, cmap=cm.coolwarm, linewidth = 0, antialiased=False)\r\n",
    "# Customize the z axis.\r\n",
    "ax1.set_zlim(-0.10, 1.40)\r\n",
    "ax1.zaxis.set_major_locator(LinearLocator(10))\r\n",
    "ax1.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\r\n",
    "\r\n",
    "# Ploting frankefunction with noise\r\n",
    "ax2 = fig.add_subplot(1,2,2, projection='3d')\r\n",
    "ax2.title.set_text(\"Plot of the Franke Function\\n(noise added)\")\r\n",
    "ax2.view_init(elev=30., azim=-25.0)\r\n",
    "ax2.set_xlabel(\"x\"); ax2.set_ylabel(\"y\"); ax2.set_zlabel(\"z\")\r\n",
    "surf2 = ax2.plot_surface(x,y,z_noisy, cmap=cm.coolwarm, linewidth = 0, antialiased=False)\r\n",
    "# Customize the z axis.\r\n",
    "ax2.set_zlim(-0.10, 1.40)\r\n",
    "ax2.zaxis.set_major_locator(LinearLocator(10))\r\n",
    "ax2.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\r\n",
    "\r\n",
    "plt.savefig(f\"{REPORT_FIGURES}franke_function_preview.pdf\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1 - Ordinary Least Squeares (OLS)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Data\r\n",
    "Defining and creating the data\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "np.random.seed(4155)\r\n",
    "n = 1000 # The number of point in the franke function\r\n",
    "x = np.random.rand(n)\r\n",
    "y = np.random.rand(n)\r\n",
    "z = FrankeFunction(x, y) \r\n",
    "noise = 0.05 * np.random.randn(n) # Stochastic noise\r\n",
    "#noise = 0.7 * np.random.randn(n) # Stochastic noise\r\n",
    "z += noise # Adding stochastic noise"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Plot of fit for all degrees before evaluation\r\n",
    " We plot the fit up to degree 6 to get an intuition on the curvature of the fitted models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "fig = plt.figure(figsize=(8,8))\r\n",
    "degrees = 6\r\n",
    "z_train_OLS = pd.DataFrame()\r\n",
    "z_hat_train_OLS = pd.DataFrame()\r\n",
    "z_test_OLS = pd.DataFrame()\r\n",
    "z_hat_test_OLS = pd.DataFrame()\r\n",
    "\r\n",
    "# TODO: Must fix so that training and test data are used. \r\n",
    "# Must evalute model using MSE from traning and test\r\n",
    "for degree in range(1, degrees + 1):\r\n",
    "    X = create_X(x, y, degree) # Design MatrixS\r\n",
    "    model = OLS() # The model\r\n",
    "    model.fit(X, z) # Fitting the model\r\n",
    "    z_hat = model.predict(X) # predict on train data\r\n",
    "    \r\n",
    "    # Plot\r\n",
    "    ax = fig.add_subplot(3,2, degree, projection='3d')\r\n",
    "    ax.view_init(elev=30., azim=-25.0)\r\n",
    "    ax.title.set_text(f\"OLS/Linear fit of degree{degree}\")\r\n",
    "    ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\r\n",
    "    ax.scatter3D(y, x, z_hat, c=z_hat ,marker = '.', cmap=cm.coolwarm)\r\n",
    "fig.suptitle(\"OLS fit to the Franke Function\")\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig(f\"{REPORT_FIGURES}franke_function_OLS_fit.pdf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 - Finding degree/model complexity for the optimal OLS fit\r\n",
    "Approximate the franke function using ordinary least squares\r\n",
    "We estimate the franke functinon using polynomials up to 6th degree. We than look at the MSE scores to look for overfitting. We use the MSE score values from the test data to determine overfit together with the curvature of the evaluation plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confidence intervall \r\n",
    "$$CI_{0.95}(\\hat\\beta_i) = [\\hat\\beta_i-1.96 SE(\\hat\\beta_i), \\hat\\beta_i+1.96 SE(\\hat\\beta_i)] =\\hat\\beta_i \\pm 1.96\\hat \\sigma(\\hat\\beta_i)$$ \r\n",
    "In order to estimate the variance of the $i$-th beta values: $$\\sigma^2 (\\beta_i ) = \\sigma^2 [(X^{T} X)^{-1}]_{ii}$$\r\n",
    "However, $\\sigma$ is unkown and can be generaly estimated as followed:\r\n",
    "$$\\hat\\sigma^2 = \\frac{\\sum_{i=0}^{N-1}(y_i - \\hat y_i)^2}{N}$$\r\n",
    "For simplification purposes, we N instead of N-p-1 in the denominator.<br>\r\n",
    "To get the variance estimate of each $\\beta$ component one must calculate the variance with respect to the diagonal elements of $(X^TX)^{-1}$ Estimated standard error is the square root of $\\hat\\sigma^2$, where the estimate for variance $\\hat\\sigma^2$ is:\r\n",
    "$$\\hat\\sigma^2 = \\frac{\\sum_{i=0}^{N-1}(y_i - \\hat y_i)^2}{N}(X^TX)^{-1}$$\r\n",
    "Where y is the true value, and $\\hat y$ being the predicted value. <br>\r\n",
    "The variance estimate of each $\\hat\\beta$ estimate can be written as:\r\n",
    "$$\\hat\\sigma_{\\hat\\beta_i}^2 = \\hat\\sigma^2(X^TX)_{i,i}^{-1}$$\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "degrees = 6\r\n",
    "z_train_OLS = pd.DataFrame()\r\n",
    "z_hat_train_OLS = pd.DataFrame()\r\n",
    "z_test_OLS = pd.DataFrame()\r\n",
    "z_hat_test_OLS = pd.DataFrame()\r\n",
    "coeffs_df = pd.DataFrame()\r\n",
    "\r\n",
    "for degree in range(1, degrees+1):\r\n",
    "    X = create_X(x, y, degree) # Design Matrix\r\n",
    "    \r\n",
    "    # Scaling data and splitting it into training and test sets\r\n",
    "    #X_train, X_test, z_train, z_test = prepare_data(X, z, test_size=0.2, shuffle=True, scale_X=False, scale_t=False)\r\n",
    "    X_train, X_test, z_train, z_test = prepare_data(X, z, test_size=0.2, shuffle=True, scale_X=False, scale_t=False, random_state=4155)\r\n",
    "    \r\n",
    "    # Model construction, fitting, and predictions\r\n",
    "    model = OLS() # The model\r\n",
    "    model.fit(X_train, z_train) # Fitting the model\r\n",
    "    z_hat_train = model.predict(X_train) # predict on train data\r\n",
    "    z_hat_test = model.predict(X_test) # predict on test data\r\n",
    "    \r\n",
    "    # Evaluatation metrics\r\n",
    "    MSE_score_train = MSE(z_train, z_hat_train)\r\n",
    "    R2_score_train = R2(z_train, z_hat_train)\r\n",
    "    MSE_score_test = MSE(z_test, z_hat_test)\r\n",
    "    R2_score_test = R2(z_test, z_hat_test)\r\n",
    "    \r\n",
    "    # Estimated standard error for the beta coefficients\r\n",
    "    N, P = X_train.shape\r\n",
    "    #var_hat = (1/(N-P-1)) * np.sum((z_train - z_hat_train)**2)\r\n",
    "    var_hat = (1/N) * np.sum((z_train - z_hat_train)**2) # Estimated variance\r\n",
    "    invXTX_diag = np.diag(np.linalg.inv(X_train.T @ X_train)) \r\n",
    "    SE_betas = np.sqrt(var_hat * invXTX_diag) # Standard Error\r\n",
    "\r\n",
    "    # Calculating 95% confidence intervall\r\n",
    "    betas = model.get_all_betas()\r\n",
    "    CI_lower_all_betas = betas - (1.96 * SE_betas)\r\n",
    "    CI_upper_all_betas = betas + (1.96 * SE_betas)\r\n",
    "    CL = np.zeros((CI_upper_all_betas.shape[0],2))\r\n",
    "    CL[:,0] = CI_lower_all_betas\r\n",
    "    CL[:,1] = CI_upper_all_betas\r\n",
    "    \r\n",
    "    # Printing results\r\n",
    "    print(f\"Degree: {degree}\")\r\n",
    "    print(f\"Train data - Mean Square Error: {MSE_score_train}\")\r\n",
    "    print(f\"Train data - R2 score: {R2_score_train}\")\r\n",
    "    print(f\"Test data - Mean Square Error: {MSE_score_test}\")\r\n",
    "    print(f\"Test data - R2 score: {R2_score_test}\")\r\n",
    "    print(f\"Estimated variance: {var_hat}\")\r\n",
    "    print(f\"Beta - values{betas}\")\r\n",
    "    print(f\"Beta - Std Errors: {SE_betas}\")\r\n",
    "    print(f\"Beta - Confidence Interval (CI):\\n{CL}\\n\")\r\n",
    "\r\n",
    "    # Constructing dataframe for beta coefficients\r\n",
    "    degs = np.zeros(betas.shape[0]); degs.fill(degree)\r\n",
    "    df = pd.DataFrame.from_dict({\"degree\" :degs,\r\n",
    "                                 \"coeff name\": [f\"b{i}\" for i in range(1,betas.shape[0]+1)],\r\n",
    "                                 \"coeff value\": np.round(betas, decimals=4),\r\n",
    "                                 \"Std Error\": np.round(SE_betas, decimals=4),\r\n",
    "                                 \"CI lower\":np.round(CI_lower_all_betas, decimals=4), \r\n",
    "                                 \"CI_upper\":np.round(CI_upper_all_betas, decimals=4)},\r\n",
    "                                 orient='index').T\r\n",
    "    coeffs_df = pd.concat([coeffs_df,df], axis=0)\r\n",
    "        \r\n",
    "    # Filling up dataframes for train and test evaluation\r\n",
    "    z_train_OLS[degree] = z_train.flatten() \r\n",
    "    z_hat_train_OLS[degree] = z_hat_train.flatten()\r\n",
    "    z_test_OLS[degree] = z_test.flatten()\r\n",
    "    z_hat_test_OLS[degree] = z_hat_test.flatten()\r\n",
    "\r\n",
    "\r\n",
    "# MSE calculations for all lambda values\r\n",
    "mse_scores_train = ((z_train_OLS - z_hat_train_OLS) ** 2).mean()\r\n",
    "mse_scores_test = ((z_test_OLS - z_hat_test_OLS) ** 2).mean()\r\n",
    "# R2 calculations for all lambda values\r\n",
    "R2_scores_train = 1 - ((z_train_OLS - z_hat_train_OLS) ** 2).sum() / ((z_train_OLS - z_train_OLS.mean())**2).sum() \r\n",
    "R2_scores_test = 1 - ((z_test_OLS - z_hat_test_OLS) ** 2).sum() / ((z_test_OLS - z_test_OLS.mean())**2).sum()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Degree: 1\n",
      "Train data - Mean Square Error: 0.025705732854019104\n",
      "Train data - R2 score: 0.7031508294717949\n",
      "Test data - Mean Square Error: 0.027876124759345942\n",
      "Test data - R2 score: 0.6325532503021353\n",
      "Estimated variance: 0.025705732854019107\n",
      "Beta - values[ 1.00324084 -0.50686336 -0.67486023]\n",
      "Beta - Std Errors: [0.01458445 0.01942289 0.01953836]\n",
      "Beta - Confidence Interval (CI):\n",
      "[[ 0.97465533  1.03182636]\n",
      " [-0.54493222 -0.46879451]\n",
      " [-0.71315542 -0.63656504]]\n",
      "\n",
      "Degree: 2\n",
      "Train data - Mean Square Error: 0.018516237398350607\n",
      "Train data - R2 score: 0.7861749461017866\n",
      "Test data - Mean Square Error: 0.020834631952430956\n",
      "Test data - R2 score: 0.7253700843225939\n",
      "Estimated variance: 0.018516237398350607\n",
      "Beta - values[ 1.18509412 -1.14137855 -0.71854823  0.1786246   0.93165135 -0.40780861]\n",
      "Beta - Std Errors: [0.02320715 0.07159262 0.0703001  0.06360226 0.05666718 0.06344847]\n",
      "Beta - Confidence Interval (CI):\n",
      "[[ 1.13960811  1.23058014]\n",
      " [-1.28170008 -1.00105702]\n",
      " [-0.85633642 -0.58076004]\n",
      " [ 0.05396418  0.30328502]\n",
      " [ 0.82058368  1.04271902]\n",
      " [-0.53216761 -0.28344961]]\n",
      "\n",
      "Degree: 3\n",
      "Train data - Mean Square Error: 0.009690043758810513\n",
      "Train data - R2 score: 0.8880996130894135\n",
      "Test data - Mean Square Error: 0.012039026185947894\n",
      "Test data - R2 score: 0.8413086080025913\n",
      "Estimated variance: 0.009690043758810513\n",
      "Beta - values[ 1.04008487 -0.80491151  1.21520782 -1.23760554  2.40595665 -6.45801251\n",
      "  0.90784728  0.06702542 -1.55072839  4.58388857]\n",
      "Beta - Std Errors: [0.02794986 0.14950238 0.14227682 0.2985933  0.22796604 0.28606616\n",
      " 0.18992253 0.15803755 0.15543409 0.18387436]\n",
      "Beta - Confidence Interval (CI):\n",
      "[[ 0.98530313  1.0948666 ]\n",
      " [-1.09793618 -0.51188685]\n",
      " [ 0.93634525  1.49407039]\n",
      " [-1.8228484  -0.65236268]\n",
      " [ 1.95914321  2.85277009]\n",
      " [-7.01870219 -5.89732283]\n",
      " [ 0.53559912  1.28009545]\n",
      " [-0.24272817  0.37677901]\n",
      " [-1.8553792  -1.24607758]\n",
      " [ 4.22349483  4.94428231]]\n",
      "\n",
      "Degree: 4\n",
      "Train data - Mean Square Error: 0.006144753702980896\n",
      "Train data - R2 score: 0.9290405354249683\n",
      "Test data - Mean Square Error: 0.007653595379794188\n",
      "Test data - R2 score: 0.8991147883686702\n",
      "Estimated variance: 0.006144753702980897\n",
      "Beta - values[  0.64620112   3.88875298   2.95165517 -18.52161788  -1.40009801\n",
      " -11.92788886  23.99368174   7.60482498   0.55132832  11.75536508\n",
      " -10.09919137  -5.48121774   0.88940296  -1.94667741  -3.02788383]\n",
      "Beta - Std Errors: [0.0339705  0.27348165 0.25305196 0.89185013 0.66452147 0.84990158\n",
      " 1.22808647 0.90415598 0.89735252 1.20123391 0.59968937 0.52014711\n",
      " 0.47826836 0.49300857 0.59072266]\n",
      "Beta - Confidence Interval (CI):\n",
      "[[  0.57961893   0.71278331]\n",
      " [  3.35272894   4.42477702]\n",
      " [  2.45567333   3.44763701]\n",
      " [-20.26964413 -16.77359163]\n",
      " [ -2.70256008  -0.09763594]\n",
      " [-13.59369595 -10.26208177]\n",
      " [ 21.58663226  26.40073122]\n",
      " [  5.83267927   9.37697069]\n",
      " [ -1.20748261   2.31013925]\n",
      " [  9.40094662  14.10978353]\n",
      " [-11.27458254  -8.9238002 ]\n",
      " [ -6.50070608  -4.4617294 ]\n",
      " [ -0.04800301   1.82680894]\n",
      " [ -2.9129742   -0.98038062]\n",
      " [ -4.18570026  -1.87006741]]\n",
      "\n",
      "Degree: 5\n",
      "Train data - Mean Square Error: 0.004212992901183912\n",
      "Train data - R2 score: 0.9513484616346145\n",
      "Test data - Mean Square Error: 0.005336577838497332\n",
      "Test data - R2 score: 0.9296563565347055\n",
      "Estimated variance: 0.004212992901183912\n",
      "Beta - values[  0.39697016   7.73917795   3.58343182 -34.28239272 -14.56963357\n",
      "  -7.10552833  49.97737581  41.16440844  21.82707641 -12.76426436\n",
      " -27.46428216 -48.31864005  -6.56477559 -31.98851887  34.77143253\n",
      "   3.72606431  16.51511117   9.5695492   -4.93064654  17.45115961\n",
      " -18.68838704]\n",
      "Beta - Std Errors: [0.03743111 0.42813553 0.40088274 2.07477515 1.50266542 1.99931183\n",
      " 4.681017   3.3134085  3.3213699  4.62508546 4.88486092 3.66382283\n",
      " 3.28909898 3.72128258 4.94754543 1.90761303 1.68696491 1.63098423\n",
      " 1.58353629 1.664932   1.9722108 ]\n",
      "Beta - Confidence Interval (CI):\n",
      "[[ 3.23605175e-01  4.70335141e-01]\n",
      " [ 6.90003231e+00  8.57832359e+00]\n",
      " [ 2.79770165e+00  4.36916200e+00]\n",
      " [-3.83489520e+01 -3.02158334e+01]\n",
      " [-1.75148578e+01 -1.16244093e+01]\n",
      " [-1.10241795e+01 -3.18687714e+00]\n",
      " [ 4.08025825e+01  5.91521691e+01]\n",
      " [ 3.46701278e+01  4.76586891e+01]\n",
      " [ 1.53171914e+01  2.83369614e+01]\n",
      " [-2.18294319e+01 -3.69909685e+00]\n",
      " [-3.70386096e+01 -1.78899548e+01]\n",
      " [-5.54997328e+01 -4.11375473e+01]\n",
      " [-1.30114096e+01 -1.18141598e-01]\n",
      " [-3.92822327e+01 -2.46948050e+01]\n",
      " [ 2.50742435e+01  4.44686216e+01]\n",
      " [-1.28572359e-02  7.46498585e+00]\n",
      " [ 1.32086599e+01  1.98215624e+01]\n",
      " [ 6.37282011e+00  1.27662783e+01]\n",
      " [-8.03437768e+00 -1.82691541e+00]\n",
      " [ 1.41878929e+01  2.07144263e+01]\n",
      " [-2.25539202e+01 -1.48228539e+01]]\n",
      "\n",
      "Degree: 6\n",
      "Train data - Mean Square Error: 0.003389701456603938\n",
      "Train data - R2 score: 0.9608558109801641\n",
      "Test data - Mean Square Error: 0.004262309679272696\n",
      "Test data - R2 score: 0.9438167302171578\n",
      "Estimated variance: 0.003389701456603938\n",
      "Beta - values[   0.58313281    1.76206554    3.27236247   11.58799377   -1.88640926\n",
      "   -4.49444482 -102.74383108  -30.29475441   28.89335888  -38.79951581\n",
      "  229.16507111   61.27000864   74.17575622 -100.04206215  110.43541402\n",
      " -207.95592181  -50.98909013  -89.32876147  -18.12656267   94.33253848\n",
      " -103.23835526   67.80656073   14.80068191   30.26346911   25.12051525\n",
      "  -12.49586133  -25.44729072   32.54933663]\n",
      "Beta - Std Errors: [ 0.04060969  0.6555081   0.63894536  4.50606955  3.18187014  4.3806141\n",
      " 14.82526149  9.94116553 10.65029458 14.53258755 25.08595038 17.23077889\n",
      " 16.02692212 18.48598725 25.01856642 21.00085596 15.48896543 14.13538263\n",
      " 14.39056666 16.2024295  21.33148556  6.87418611  5.81890579  5.81994841\n",
      "  5.97457999  6.01478942  5.96058383  7.1049818 ]\n",
      "Beta - Confidence Interval (CI):\n",
      "[[   0.50353781    0.66272781]\n",
      " [   0.47726967    3.04686141]\n",
      " [   2.02002956    4.52469538]\n",
      " [   2.75609745   20.4198901 ]\n",
      " [  -8.12287473    4.35005621]\n",
      " [ -13.08044846    4.09155883]\n",
      " [-131.80134361  -73.68631856]\n",
      " [ -49.77943885  -10.81006997]\n",
      " [   8.0187815    49.76793626]\n",
      " [ -67.28338741  -10.3156442 ]\n",
      " [ 179.99660836  278.33353386]\n",
      " [  27.49768202   95.04233527]\n",
      " [  42.76298887  105.58852356]\n",
      " [-136.27459716  -63.80952714]\n",
      " [  61.39902383  159.4718042 ]\n",
      " [-249.11759949 -166.79424414]\n",
      " [ -81.34746238  -20.63071788]\n",
      " [-117.03411142  -61.62341152]\n",
      " [ -46.33207332   10.07894798]\n",
      " [  62.57577665  126.08930031]\n",
      " [-145.04806696  -61.42864357]\n",
      " [  54.33315595   81.27996552]\n",
      " [   3.39562656   26.20573727]\n",
      " [  18.85637024   41.67056799]\n",
      " [  13.41033847   36.83069204]\n",
      " [ -24.28484859   -0.70687407]\n",
      " [ -37.13003504  -13.7645464 ]\n",
      " [  18.62357231   46.47510096]]\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Plots\r\n",
    "plt.figure(figsize=(12,8))\r\n",
    "plt.plot(np.arange(1,degrees+1), mse_scores_train, c=\"c\", label=\"Training data\")\r\n",
    "plt.plot(np.arange(1,degrees+1), mse_scores_test, c=\"m\", label=\"Test data\")\r\n",
    "plt.xlabel(\"Model complexity - Number of polynomial degrees\")\r\n",
    "plt.ylabel(\"MSE\")\r\n",
    "plt.title(\"Training evaluation on OLS regression fit\")\r\n",
    "plt.legend()\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig(f\"{REPORT_FIGURES}franke_function_OLS_evaluate_fit.pdf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 Analysis of plots and training metrics\r\n",
    "Do the analysis.......\r\n",
    "\r\n",
    "Conclusion:<br>\r\n",
    "Based on the analysis, we conclude that a model complexity of degree 5 yields the most optimal fit."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.5 plot of the model using the most optimal parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "optimal_degree = 5\r\n",
    "X = create_X(x, y, optimal_degree) # Design Matrix\r\n",
    "model = OLS() # The model\r\n",
    "model.fit(X, z) # Fitting the model\r\n",
    "z_hat = model.predict(X) # predict on train data\r\n",
    "\r\n",
    "# Plot\r\n",
    "fig = plt.figure()#figsize=(8,8))\r\n",
    "ax = plt.axes(projection='3d')\r\n",
    "ax.title.set_text(f\"OLS regression fit to the Franke Function\\noptimal degree {optimal_degree},\")\r\n",
    "#ax.view_init(elev=5., azim=85.0)\r\n",
    "ax.view_init(elev=30., azim=-25.0)\r\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\r\n",
    "ax.scatter3D(y, x, z_hat, c=z_hat ,marker = '.', cmap=cm.coolwarm)\r\n",
    "plt.savefig(f\"{REPORT_FIGURES}franke_function_OLS_best_fit.pdf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "optimal_degree_coeffs = coeffs_df[coeffs_df[\"degree\"] == optimal_degree]\r\n",
    "display(optimal_degree_coeffs)\r\n",
    "optimal_degree_coeffs.to_csv(f\"{REPORT_DATA}EX1_coeffs_optimal_degree.csv\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree</th>\n",
       "      <th>coeff name</th>\n",
       "      <th>coeff value</th>\n",
       "      <th>Std Error</th>\n",
       "      <th>CI lower</th>\n",
       "      <th>CI_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b1</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.3236</td>\n",
       "      <td>0.4703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b2</td>\n",
       "      <td>7.7392</td>\n",
       "      <td>0.4281</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.5783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b3</td>\n",
       "      <td>3.5834</td>\n",
       "      <td>0.4009</td>\n",
       "      <td>2.7977</td>\n",
       "      <td>4.3692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b4</td>\n",
       "      <td>-34.2824</td>\n",
       "      <td>2.0748</td>\n",
       "      <td>-38.349</td>\n",
       "      <td>-30.2158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b5</td>\n",
       "      <td>-14.5696</td>\n",
       "      <td>1.5027</td>\n",
       "      <td>-17.5149</td>\n",
       "      <td>-11.6244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b6</td>\n",
       "      <td>-7.1055</td>\n",
       "      <td>1.9993</td>\n",
       "      <td>-11.0242</td>\n",
       "      <td>-3.1869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b7</td>\n",
       "      <td>49.9774</td>\n",
       "      <td>4.681</td>\n",
       "      <td>40.8026</td>\n",
       "      <td>59.1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b8</td>\n",
       "      <td>41.1644</td>\n",
       "      <td>3.3134</td>\n",
       "      <td>34.6701</td>\n",
       "      <td>47.6587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b9</td>\n",
       "      <td>21.8271</td>\n",
       "      <td>3.3214</td>\n",
       "      <td>15.3172</td>\n",
       "      <td>28.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b10</td>\n",
       "      <td>-12.7643</td>\n",
       "      <td>4.6251</td>\n",
       "      <td>-21.8294</td>\n",
       "      <td>-3.6991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b11</td>\n",
       "      <td>-27.4643</td>\n",
       "      <td>4.8849</td>\n",
       "      <td>-37.0386</td>\n",
       "      <td>-17.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b12</td>\n",
       "      <td>-48.3186</td>\n",
       "      <td>3.6638</td>\n",
       "      <td>-55.4997</td>\n",
       "      <td>-41.1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b13</td>\n",
       "      <td>-6.5648</td>\n",
       "      <td>3.2891</td>\n",
       "      <td>-13.0114</td>\n",
       "      <td>-0.1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b14</td>\n",
       "      <td>-31.9885</td>\n",
       "      <td>3.7213</td>\n",
       "      <td>-39.2822</td>\n",
       "      <td>-24.6948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b15</td>\n",
       "      <td>34.7714</td>\n",
       "      <td>4.9475</td>\n",
       "      <td>25.0742</td>\n",
       "      <td>44.4686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b16</td>\n",
       "      <td>3.7261</td>\n",
       "      <td>1.9076</td>\n",
       "      <td>-0.0129</td>\n",
       "      <td>7.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b17</td>\n",
       "      <td>16.5151</td>\n",
       "      <td>1.687</td>\n",
       "      <td>13.2087</td>\n",
       "      <td>19.8216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b18</td>\n",
       "      <td>9.5695</td>\n",
       "      <td>1.631</td>\n",
       "      <td>6.3728</td>\n",
       "      <td>12.7663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b19</td>\n",
       "      <td>-4.9306</td>\n",
       "      <td>1.5835</td>\n",
       "      <td>-8.0344</td>\n",
       "      <td>-1.8269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b20</td>\n",
       "      <td>17.4512</td>\n",
       "      <td>1.6649</td>\n",
       "      <td>14.1879</td>\n",
       "      <td>20.7144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.0</td>\n",
       "      <td>b21</td>\n",
       "      <td>-18.6884</td>\n",
       "      <td>1.9722</td>\n",
       "      <td>-22.5539</td>\n",
       "      <td>-14.8229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   degree coeff name coeff value Std Error CI lower CI_upper\n",
       "0     5.0         b1       0.397    0.0374   0.3236   0.4703\n",
       "1     5.0         b2      7.7392    0.4281      6.9   8.5783\n",
       "2     5.0         b3      3.5834    0.4009   2.7977   4.3692\n",
       "3     5.0         b4    -34.2824    2.0748  -38.349 -30.2158\n",
       "4     5.0         b5    -14.5696    1.5027 -17.5149 -11.6244\n",
       "5     5.0         b6     -7.1055    1.9993 -11.0242  -3.1869\n",
       "6     5.0         b7     49.9774     4.681  40.8026  59.1522\n",
       "7     5.0         b8     41.1644    3.3134  34.6701  47.6587\n",
       "8     5.0         b9     21.8271    3.3214  15.3172   28.337\n",
       "9     5.0        b10    -12.7643    4.6251 -21.8294  -3.6991\n",
       "10    5.0        b11    -27.4643    4.8849 -37.0386   -17.89\n",
       "11    5.0        b12    -48.3186    3.6638 -55.4997 -41.1375\n",
       "12    5.0        b13     -6.5648    3.2891 -13.0114  -0.1181\n",
       "13    5.0        b14    -31.9885    3.7213 -39.2822 -24.6948\n",
       "14    5.0        b15     34.7714    4.9475  25.0742  44.4686\n",
       "15    5.0        b16      3.7261    1.9076  -0.0129    7.465\n",
       "16    5.0        b17     16.5151     1.687  13.2087  19.8216\n",
       "17    5.0        b18      9.5695     1.631   6.3728  12.7663\n",
       "18    5.0        b19     -4.9306    1.5835  -8.0344  -1.8269\n",
       "19    5.0        b20     17.4512    1.6649  14.1879  20.7144\n",
       "20    5.0        b21    -18.6884    1.9722 -22.5539 -14.8229"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('pytorch_lightning': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "cdd16a4e159c1067d9dfa51729b478ccc85a4bb59359633d71fef71fb1a46b1f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}