{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import os\r\n",
    "from common import *\r\n",
    "import pandas as pd\r\n",
    "#from mpl_toolkits.mplot3d import Axes3D\r\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\r\n",
    "\r\n",
    "os.chdir(\"../\")\r\n",
    "print(f\"Root directory: {os.getcwd()}\")\r\n",
    "\r\n",
    "plt.rcParams.update({\r\n",
    "    \"text.usetex\": True,\r\n",
    "    \"font.family\": \"serif\",\r\n",
    "    \"font.serif\": [\"Palatino\"],\r\n",
    "    \"font.size\": 10,\r\n",
    "})\r\n",
    "\r\n",
    "%matplotlib inline "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Root directory: c:\\Users\\andre\\Dropbox\\FYS-STK4155_projects\\FYS-STK4155 - Project1\\FYS-STK4155-Prj1_report\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Global variables "
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "INPUT_DATA = \"data/input_data/\"  # Path for input data\r\n",
    "REPORT_DATA = \"data/report_data/\" # Path for data ment for the report\r\n",
    "REPORT_FIGURES = \"figures/\" # Path for figures ment for the report"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Franke function 3D preview\r\n",
    "First we plot a 3D plot of the franke function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Preview plot of the franke function\r\n",
    "%matplotlib\r\n",
    "np.random.seed(4155)\r\n",
    "y = x = np.arange(0, 1, 0.05)\r\n",
    "x, y = np.meshgrid(x,y)\r\n",
    "z = FrankeFunction(x, y)\r\n",
    "noise_mesh = 0.05 * np.random.randn(z.shape[0], z.shape[1])\r\n",
    "z_noisy = z + noise_mesh\r\n",
    "\r\n",
    "fig = plt.figure()\r\n",
    "ax = fig.add_subplot(1,2,1, projection='3d') # Are :)steike\r\n",
    "\r\n",
    "#ax = plt.axes(projection='3d')\r\n",
    "ax.title.set_text(\"Plot of the Franke Function\")\r\n",
    "ax.view_init(elev=30., azim=-25.0)\r\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\r\n",
    "surf = ax.plot_surface(x,y,z, cmap=cm.coolwarm, linewidth = 0, antialiased=False)\r\n",
    "\r\n",
    "ax = fig.add_subplot(1,2,2, projection='3d')\r\n",
    "ax.title.set_text(\"Plot of the Franke Function (noise added)\")\r\n",
    "ax.view_init(elev=30., azim=-25.0)\r\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\r\n",
    "surf = ax.plot_surface(x,y,z_noisy, cmap=cm.coolwarm, linewidth = 0, antialiased=False)\r\n",
    "plt.savefig(f\"{REPORT_FIGURES}franke_function_preview.pdf\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1 - Ordinary Least Squeares (OLS)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Data\r\n",
    "Defining and creating the data\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "n = 2000 # The number of point in the franke function\r\n",
    "x = np.random.rand(n)\r\n",
    "y = np.random.rand(n)\r\n",
    "z = FrankeFunction(x, y) \r\n",
    "noise = 0.05 * np.random.randn(n)\r\n",
    "z += noise # Adding noise to the function values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Plot of fit for all degrees before evaluation\r\n",
    " We plot the fit up to degree 6 to get an intuition on the curvature of the fitted models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "fig = plt.figure(figsize=(8,8))\r\n",
    "degrees = 6\r\n",
    "z_train_OLS = pd.DataFrame()\r\n",
    "z_hat_train_OLS = pd.DataFrame()\r\n",
    "z_test_OLS = pd.DataFrame()\r\n",
    "z_hat_test_OLS = pd.DataFrame()\r\n",
    "\r\n",
    "# TODO: Must fix so that training and test data are used. \r\n",
    "# Must evalute model using MSE from traning and test\r\n",
    "for degree in range(1, degrees + 1):\r\n",
    "    X = create_X(x, y, degree) # Design Matrix\r\n",
    "    model = OLS() # The model\r\n",
    "    model.fit(X, z) # Fitting the model\r\n",
    "    z_hat = model.predict(X) # predict on train data\r\n",
    "    \r\n",
    "    # Plot\r\n",
    "    ax = fig.add_subplot(3,2, degree, projection='3d')\r\n",
    "    ax.view_init(elev=30., azim=-25.0)\r\n",
    "    ax.title.set_text(f\"OLS/Linear fit of degree{degree}\")\r\n",
    "    ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\r\n",
    "    ax.scatter3D(y, x, z_hat, c=z_hat ,marker = '.', cmap=cm.coolwarm)\r\n",
    "fig.suptitle(\"OLS fit to the Franke Function\")\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig(f\"{REPORT_FIGURES}franke_function_fit_OLS.pdf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 - Finding degree/model complexity for the optimal OLS fit\r\n",
    "Approximate the franke function using ordinary least squares\r\n",
    "We estimate the franke functinon using polynomials up to 6th degree. We than look at the MSE scores to look for overfitting. We use the MSE score values from the test data to determine overfit together with the curvature of the evaluation plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "degrees = 6\r\n",
    "z_train_OLS = pd.DataFrame()\r\n",
    "z_hat_train_OLS = pd.DataFrame()\r\n",
    "z_test_OLS = pd.DataFrame()\r\n",
    "z_hat_test_OLS = pd.DataFrame()\r\n",
    "\r\n",
    "# TODO: Must fix so that training and test data are used. \r\n",
    "# Must evalute model using MSE from traning and test\r\n",
    "for degree in range(1, degrees + 1):\r\n",
    "    X = create_X(x, y, degree) # Design Matrix\r\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X,z, test_size=0.2, shuffle=True, random_state=4155)\r\n",
    "    \r\n",
    "    model = OLS() # The model\r\n",
    "    model.fit(X_train, z_train) # Fitting the model\r\n",
    "    \r\n",
    "    # Predictions\r\n",
    "    z_hat_train = model.predict(X_train) # predict on train data\r\n",
    "    z_hat_test = model.predict(X_test) # predict on test data\r\n",
    "\r\n",
    "    # Evaluatation metrics\r\n",
    "    # TODO:\r\n",
    "    # Filling up dataframes\r\n",
    "    z_train_OLS[degree] = z_train.flatten() \r\n",
    "    z_hat_train_OLS[degree] = z_hat_train.flatten()\r\n",
    "    z_test_OLS[degree] = z_test.flatten()\r\n",
    "    z_hat_test_OLS[degree] = z_hat_test.flatten()\r\n",
    "\r\n",
    "\r\n",
    "# MSE calculations for all lambda values\r\n",
    "mse_scores_train = ((z_train_OLS - z_hat_train_OLS) ** 2).mean()\r\n",
    "mse_scores_test = ((z_test_OLS - z_hat_test_OLS) ** 2).mean()\r\n",
    "# R2 calculations for all lambda values\r\n",
    "R2_scores_train = 1 - ((z_train_OLS - z_hat_train_OLS) ** 2).sum() / ((z_train_OLS - z_train_OLS.mean())**2).sum() \r\n",
    "R2_scores_test = 1 - ((z_test_OLS - z_hat_test_OLS) ** 2).sum() / ((z_test_OLS - z_test_OLS.mean())**2).sum()  \r\n",
    "\r\n",
    "# Plots\r\n",
    "plt.figure(figsize=(12,8))\r\n",
    "plt.plot(np.arange(1,degrees+1), mse_scores_train, label=\"Training data\")\r\n",
    "plt.plot(np.arange(1,degrees+1), mse_scores_test, label=\"Test data\")\r\n",
    "plt.xlabel(\"Model complexity - Number of polynomial degrees\")\r\n",
    "plt.ylabel(\"MSE\")\r\n",
    "plt.title(\"Training evaluation on OLS regression fit\")\r\n",
    "plt.legend()\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig(f\"{REPORT_FIGURES}franke_function_OLS_fit_evaluation.pdf.pdf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 Analysis of plots and training metrics\r\n",
    "Do the analysis.......\r\n",
    "\r\n",
    "Conclusion:<br>\r\n",
    "Based on the analysis, we conclude that a model complexity of degree 5 yields the most optimal fit."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.5 plot of the model using the most optimal parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "degree_optimal = 5\r\n",
    "X = create_X(x, y, degree_optimal) # Design Matrix\r\n",
    "model = OLS() # The model\r\n",
    "model.fit(X, z) # Fitting the model\r\n",
    "z_hat = model.predict(X) # predict on train data\r\n",
    "\r\n",
    "# Plot\r\n",
    "fig = plt.figure()#figsize=(8,8))\r\n",
    "ax = plt.axes(projection='3d')\r\n",
    "ax.title.set_text(f\"OLS regression fit to the Franke Function\\noptimal degree {degree_optimal},\")\r\n",
    "#ax.view_init(elev=5., azim=85.0)\r\n",
    "ax.view_init(elev=30., azim=-25.0)\r\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\r\n",
    "ax.scatter3D(y, x, z_hat, c=z_hat ,marker = '.', cmap=cm.coolwarm)\r\n",
    "plt.savefig(f\"{REPORT_FIGURES}franke_function_best_fit_OLS.pdf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 - Ridge Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Data\r\n",
    "Defining and creating the data\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "features = 6\r\n",
    "#x = np.arange(0, 1, 0.05)\r\n",
    "#y = np.arange(0, 1, 0.05)\r\n",
    "X = create_X(x, y, n=features) # Design Matrix\r\n",
    "z = FrankeFunction(x,y)\r\n",
    "z += noise"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 - Finding degree/model complexity for the optimal OLS fit\r\n",
    "First we find the optimal value for the lambda parameter by splitting the input data into training and test data. Than we fit the model using different values for lambda. For each lambda value we use the mean square error on the test data evaluate how god the fit is. The best lambda value is used to fit a new model with all data (not using train-test split). <br>\r\n",
    "First we find the optimal parameter value of lambda, $\\lambda$, by evaluating overfit from evaluation plot where we plot the values for MSE for training and test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "nbf_lambdas = 300\r\n",
    "lambdas = np.logspace(-6,6, nbf_lambdas)\r\n",
    "z_train_ridge = pd.DataFrame()\r\n",
    "z_hat_train_ridge = pd.DataFrame()\r\n",
    "z_test_ridge = pd.DataFrame()\r\n",
    "z_hat_test_ridge = pd.DataFrame()\r\n",
    "\r\n",
    "for lam in lambdas:\r\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X,z, test_size=0.2, shuffle=True)\r\n",
    "    model = RidgeRegression(lam) # The model\r\n",
    "    model.fit(X_train, z_train) # Fitting the model\r\n",
    "   \r\n",
    "    # Predictions\r\n",
    "    z_hat_train = model.predict(X_train) # predict on train data\r\n",
    "    z_hat_test = model.predict(X_test) # predict on test data\r\n",
    "\r\n",
    "    # Filling up dataframes\r\n",
    "    z_train_ridge[lam] = z_train.flatten() \r\n",
    "    z_hat_train_ridge[lam] = z_hat_train.flatten()\r\n",
    "    z_test_ridge[lam] = z_test.flatten()\r\n",
    "    z_hat_test_ridge[lam] = z_hat_test.flatten()\r\n",
    "\r\n",
    "\r\n",
    "# MSE calculations for all lambda values\r\n",
    "mse_scores_train = ((z_train_ridge - z_hat_train_ridge) ** 2).mean()\r\n",
    "mse_scores_test = ((z_test_ridge - z_hat_test_ridge) ** 2).mean()\r\n",
    "# R2 calculations for all lambda values\r\n",
    "R2_scores_train = 1 - ((z_train_ridge - z_hat_train_ridge) ** 2).sum() / ((z_train_ridge - z_train_ridge.mean())**2).sum() \r\n",
    "R2_scores_test = 1 - ((z_test_ridge - z_hat_test_ridge) ** 2).sum() / ((z_test_ridge - z_test_ridge.mean())**2).sum()  \r\n",
    "\r\n",
    "# Plots\r\n",
    "plt.figure(figsize=(12,8))\r\n",
    "plt.plot(-np.log(lambdas), mse_scores_train, label=\"Training data\")\r\n",
    "plt.plot(-np.log(lambdas), mse_scores_test, label=\"Test data\")\r\n",
    "#plt.plot(mse_scores_train,-np.log(lambdas), label=\"Training data\")\r\n",
    "#plt.plot(mse_scores_test,-np.log(lambdas), label=\"Test data\")\r\n",
    "plt.xlabel(\"log(lambda)\")\r\n",
    "plt.ylabel(\"MSE\")\r\n",
    "plt.title(\"Training evaluation on Ridge regression fit\")\r\n",
    "plt.legend()\r\n",
    "plt.savefig(f\"{REPORT_FIGURES}franke_function_Ridge_fit_evaluation.pdf\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-9-c531ee5f723e>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_train_ridge[lam] = z_train.flatten()\n",
      "<ipython-input-9-c531ee5f723e>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_hat_train_ridge[lam] = z_hat_train.flatten()\n",
      "<ipython-input-9-c531ee5f723e>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_test_ridge[lam] = z_test.flatten()\n",
      "<ipython-input-9-c531ee5f723e>:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_hat_test_ridge[lam] = z_hat_test.flatten()\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4 Analysis of plots and training metrics\r\n",
    "Do the analysis.......\r\n",
    "\r\n",
    "Conclusion:<br>\r\n",
    "Based on the analysis, we conclude that a model complexity of degree 5 yields the most optimal fit."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.5 plot of the model using the most optimal parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "lam = -1.1\r\n",
    "model = RidgeRegression(lam) # The model\r\n",
    "model.fit(X, z) # Fitting the model\r\n",
    "\r\n",
    "# Predictions\r\n",
    "z_hat = model.predict(X) # predict on train data\r\n",
    "\r\n",
    "# Evaluatation metrics\r\n",
    "# TODO:\r\n",
    "results_df = pd.DataFrame(columns=[\"MSE\", \"R2-score\"], index=[\"Training data\", \"Test data\"])\r\n",
    "results_df[\"MSE\"] = MSE(z, z_hat)\r\n",
    "results_df[\"R2-score\"] = R2(z, z_hat)\r\n",
    "results_df.to_csv(f\"{REPORT_DATA}redge_reg_lambda_{lam}.csv\")\r\n",
    "\r\n",
    "# Plot\r\n",
    "fig = plt.figure()#figsize=(8,8))\r\n",
    "ax = plt.axes(projection='3d')\r\n",
    "ax.title.set_text(f\"Ridge regression fit to the Franke Function\\nDegree {degree},$\\lambda$:{lam}\")\r\n",
    "#ax.view_init(elev=5., azim=85.0)\r\n",
    "ax.view_init(elev=30., azim=-25.0)\r\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\r\n",
    "ax.scatter3D(x,y,z,c=z, cmap=cm.coolwarm, marker = '.')\r\n",
    "plt.savefig(f\"{REPORT_FIGURES}franke_function_Ridge_fit.pdf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('pytorch1': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "4100b45d1ec7c24b8fe1569d39871ffb9fcc213dcc50046fc68fe247fbf6e84f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}