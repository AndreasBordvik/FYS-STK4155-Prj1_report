{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import os\r\n",
    "from common import *\r\n",
    "import pandas as pd\r\n",
    "#from mpl_toolkits.mplot3d import Axes3D\r\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\r\n",
    "%matplotlib "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### System preferences"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%matplotlib inline \r\n",
    "#os.chdir(\"../\")\r\n",
    "print(f\"Root directory: {os.getcwd()}\")\r\n",
    "\r\n",
    "plt.rcParams.update({\r\n",
    "    \"text.usetex\": True,\r\n",
    "    \"font.family\": \"serif\",\r\n",
    "    \"font.serif\": [\"Palatino\"],\r\n",
    "    \"font.size\": 10,\r\n",
    "})"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Root directory: c:\\Users\\andre\\Dropbox\\FYS-STK4155_H21\\projects\\prj1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First we plot a 3D plot of the franke function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Preview plot of the franke function\r\n",
    "%matplotlib\r\n",
    "np.random.seed(4155)\r\n",
    "y = x = np.arange(0, 1, 0.05)\r\n",
    "x, y = np.meshgrid(x,y)\r\n",
    "z = FrankeFunction(x, y)\r\n",
    "noise_mesh = 0.05 * np.random.randn(z.shape[0], z.shape[1])\r\n",
    "z_noisy = z + noise_mesh\r\n",
    "\r\n",
    "fig = plt.figure()\r\n",
    "ax = fig.add_subplot(1,2,1, projection='3d') # Are :)steike\r\n",
    "\r\n",
    "#ax = plt.axes(projection='3d')\r\n",
    "ax.title.set_text(\"Plot of the Franke Function\")\r\n",
    "ax.view_init(elev=30., azim=-25.0)\r\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\r\n",
    "surf = ax.plot_surface(x,y,z, cmap=cm.coolwarm, linewidth = 0, antialiased=False)\r\n",
    "\r\n",
    "ax = fig.add_subplot(1,2,2, projection='3d')\r\n",
    "ax.title.set_text(\"Plot of the Franke Function (noise added)\")\r\n",
    "ax.view_init(elev=30., azim=-25.0)\r\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\r\n",
    "surf = ax.plot_surface(x,y,z_noisy, cmap=cm.coolwarm, linewidth = 0, antialiased=False)\r\n",
    "plt.savefig(\"franke_function_preview.pdf\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining and creating the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "n = 2000\r\n",
    "x = np.random.rand(n)\r\n",
    "y = np.random.rand(n)\r\n",
    "z = FrankeFunction(x, y) \r\n",
    "noise = 0.05 * np.random.randn(n)\r\n",
    "z += noise # Adding noise to the function values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Approximate the franke function using ordinary least squares\r\n",
    "We estimate the franke functinon using polynomials up to 6th degree. We than look at the MSE scores to look for overfitting. We use the MSE score values from the test data to determine overfit together with the corveture of the plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def randrange(n, vmin, vmax):\r\n",
    "    return (vmax - vmin)*np.random.rand(n) + vmin\r\n",
    "\r\n",
    "fig = plt.figure(figsize=(8,8))\r\n",
    "degrees = 6\r\n",
    "for degree in range(1, degrees + 1):\r\n",
    "    X = create_X(x, y, degree) # Design Matrix\r\n",
    "    model = OLS() # The model\r\n",
    "    model.fit(X, z) # Fitting the model\r\n",
    "    z_hat = model.predict(X) # Predicting z_hat values\r\n",
    "\r\n",
    "    # Evaluatation metrics\r\n",
    "    # TODO:\r\n",
    "    zs = randrange(n, 0, 50)\r\n",
    "    # Plot\r\n",
    "    ax = fig.add_subplot(3,2, degree, projection='3d')\r\n",
    "    ax.view_init(elev=30., azim=-25.0)\r\n",
    "    ax.title.set_text(f\"OLS/Linear fit of degree{degree}\")\r\n",
    "    ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\r\n",
    "    ax.scatter3D(y, x, z_hat, c=z_hat ,marker = '.', cmap=cm.coolwarm)\r\n",
    "fig.suptitle(\"OLS fit to the Franke Function\")\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig(\"franke_function_fit_OLS.pdf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Approximate the franke function using Ridge regression\r\n",
    "First we find the optimal value for the lambda parameter by splitting the input data into training and test data. Than we fit the model using different values for lambda. For each lambda value we use the mean square error on the test data evaluate how god the fit is. The best lambda value is used to fit a new model with all data (not using train-test split). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we find the optimal parameter value of lambda, $\\lambda$, by evaluating overfit from evaluation plot where we plot the values for MSE for training and test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "features = 6\r\n",
    "#x = np.arange(0, 1, 0.05)\r\n",
    "#y = np.arange(0, 1, 0.05)\r\n",
    "\r\n",
    "X = create_X(x, y, n=features) # Design Matrix\r\n",
    "z = FrankeFunction(x,y)\r\n",
    "nbf_lambdas = 20\r\n",
    "lambdas = np.logspace(-1,2, nbf_lambdas)\r\n",
    "z_train_df = pd.DataFrame()\r\n",
    "z_hat_train_df = pd.DataFrame()\r\n",
    "z_test_df = pd.DataFrame()\r\n",
    "z_hat_test_df = pd.DataFrame()\r\n",
    "\r\n",
    "for lam in lambdas:\r\n",
    "        \r\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X,z, test_size=0.2, shuffle=True)\r\n",
    "    model = RidgeRegression(lam) # The model\r\n",
    "    model.fit(X_train, z_train) # Fitting the model\r\n",
    "   \r\n",
    "    # Predictions\r\n",
    "    z_hat_train = model.predict(X_train) # predict on train data\r\n",
    "    z_hat_test = model.predict(X_test) # predict on test data\r\n",
    "    \r\n",
    "\r\n",
    "\r\n",
    "    # Filling up dataframes\r\n",
    "    #z_train_df[f\"lambda_{lam}\"] = z_train.flatten() \r\n",
    "    #z_hat_train_df[f\"lambda_{lam}\"] = z_hat_train.flatten()\r\n",
    "    #z_test_df[f\"lambda_{lam}\"] = z_test.flatten()\r\n",
    "    #z_hat_test_df[f\"lambda_{lam}\"] = z_hat_test.flatten()\r\n",
    "\r\n",
    "    z_train_df[lam] = z_train.flatten() \r\n",
    "    z_hat_train_df[lam] = z_hat_train.flatten()\r\n",
    "    z_test_df[lam] = z_test.flatten()\r\n",
    "    z_hat_test_df[lam] = z_hat_test.flatten()\r\n",
    "\r\n",
    "\r\n",
    "    \r\n",
    "# MSE calculations for all lambda values\r\n",
    "mse_scores_train = ((z_train_df - z_hat_train_df) ** 2).mean()\r\n",
    "mse_scores_test = ((z_test_df - z_hat_test_df) ** 2).mean()\r\n",
    "# R2 calculations for all lambda values\r\n",
    "R2_scores_train = 1 - ((z_train_df - z_hat_train_df) ** 2).sum() / ((z_train_df - z_train_df.mean())**2).sum() \r\n",
    "R2_scores_test = 1 - ((z_test_df - z_hat_test_df) ** 2).sum() / ((z_test_df - z_test_df.mean())**2).sum()  \r\n",
    "\r\n",
    "# Plots\r\n",
    "plt.figure(figsize=(12,8))\r\n",
    "plt.plot(np.log(lambdas), mse_scores_train, label=\"Training data\")\r\n",
    "plt.plot(np.log(lambdas), mse_scores_test, label=\"Test data\")\r\n",
    "plt.xlabel(\"log(lambda)\")\r\n",
    "plt.ylabel(\"MSE\")\r\n",
    "plt.title(\"Training evaluation on Ridge regression fit\")\r\n",
    "plt.legend()\r\n",
    "plt.savefig(\"Franke Function Ridge fit evaluation.pdf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "lam = -1.1\r\n",
    "model = RidgeRegression(lam) # The model\r\n",
    "model.fit(X, z) # Fitting the model\r\n",
    "\r\n",
    "# Predictions\r\n",
    "z_hat = model.predict(X) # predict on train data\r\n",
    "\r\n",
    "# Evaluatation metrics\r\n",
    "# TODO:\r\n",
    "\r\n",
    "# Plot\r\n",
    "fig = plt.figure()#figsize=(8,8))\r\n",
    "ax = plt.axes(projection='3d')\r\n",
    "ax.title.set_text(f\"Ridge regression fit to the Franke Function\\nDegree {degree},$\\lambda$:{lam}\")\r\n",
    "#ax.view_init(elev=5., azim=85.0)\r\n",
    "ax.view_init(elev=30., azim=-25.0)\r\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\r\n",
    "ax.scatter3D(x,y,z,c=z, cmap=cm.coolwarm, marker = '.')\r\n",
    "plt.savefig(\"franke_function_Ridge_fit.pdf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('pytorch_lightning': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "cdd16a4e159c1067d9dfa51729b478ccc85a4bb59359633d71fef71fb1a46b1f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}